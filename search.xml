<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[新词发现(1)——核心代码解读]]></title>
      <url>%2F2019%2F03%2F09%2F%E6%96%B0%E8%AF%8D%E5%8F%91%E7%8E%B0-1-%E2%80%94%E2%80%94%E6%A0%B8%E5%BF%83%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%2F</url>
      <content type="text"><![CDATA[主要思想是利用三个指标，即频数、凝固度（取对数之后就是点互信息）与自由度（边界熵）来判断一个片段是否成词，并参考了苏神的代码，详见参考部分。 前奏读取外部文章，作为一个字符串str格式 12f = open('天龙八部.txt', 'r', encoding='gbk', errors='ignore')s = f.read() 使用正则表达式，去除不需要的标点符号1234# 去掉标点字drop_dict = [u'，', u'\n', u'。', u'、', u'：', u'(', u')', u'[', u']', u'.', u',', u' ', u'\u3000', u'”', u'“', u'？', u'?', u'！', u'‘', u'’', u'…']for i in drop_dict: s = s.replace(i, '') 一些阈值初始设定 12345myre = &#123;2:'(..)', 3:'(...)', 4:'(....)', 5:'(.....)', 6:'(......)', 7:'(.......)'&#125;min_count = 10 #最小频数min_support = 30 #内部凝固程度，越大表示越相关max_sep = 3 #最大候选词的字数min_s = 3 #衡量词语的自由运用程度，越大说明越有可能独立成词 内部凝固度通过list()方法把str按单字符切分，并逐字统计 12345# t为切分的词组并词频统计t = []t.append(pd.Series(list(s)).value_counts()) tsum = t[0].sum() #总字数rt = [] #只存放词组 假设为2-grams模型，一段文本诸如&quot;慕容公子真厉害&quot;，会被依次切分为&quot;慕容/公子/真厉&quot;与&quot;容公/子真/厉害&quot;，合并后进行词频统计，并剔除出现次数过小的词语（限制出现频数）。 接着，再计算一个词语的内部凝固程度（取对数后即为点互信息PMI），剔除掉低于阈值的词语。 1234567891011121314for m in range(2, max_sep+1): print(u'正在生成%s字词...' %m) t.append([]) # 切分 for i in range(m): t[m-1] = t[m-1] +re.findall(myre[m], s[i:]) t[m-1] = pd.Series(t[m-1]).value_counts() t[m-1] = t[m-1][t[m-1] &gt; min_count] #最小次数筛选 tt = t[m-1][:] # PMI互信息 for k in range(m-1): qq = np.array(list(map(lambda ms: tsum*t[m-1][ms] / t[m-2-k][ms[:m-1-k]] / t[k][ms[m-1-k:]], tt.index))) &gt; min_support tt = tt[qq] rt.append(list(tt.index)) rt形式如下： 这里补充一点，点互信息(即PMI)衡量的是两个事物之间的相关性，具体公式如下： PMI(x,y) = log_2 \frac {P(x,y)}{p(x)p(y)}我们知道，若两个变量独立同分布，则有$p(x,y) = p(x)p(y)$, 但若$x$与$y$高度相关，则有$p(x,y) &gt; p(x)p(y)$，所以PMI越大，相关性高。放入体本文的任务里，具体为&quot;段誉&quot;俩字经常同时出现，内部凝固程度高，所以不应该切分成&#39;段&#39;/&#39;誉&#39; 信息熵第一步通过(.)%s(.)的正则方式切分出左邻字与右邻字，如&quot;慕容公子真厉害啊&quot;可切分成[(&#39;慕&#39;, &#39;容公&#39;, &#39;子&#39;), (&#39;真&#39;, &#39;厉害&#39;, &#39;啊&#39;)]的形式(n-grams=2) 然后把我们需要的中间那列作为索引并排序！intersect1d()方法可以找出两个列表之间的共同元素，之后计算左(右)邻信息熵。 其中pd.Series(pp[0][s]).value_counts()为取出交集中某个词语的全部左邻字并计数，再通过cal_s()函数计算信息熵，只取信息熵大于一定阈值的词语（如&quot;慕容&quot;），右邻信息熵同样如此，最后更新结果集rt。 123456789101112for i in range(2, max_sep+1): print(u'在进行%s字词的最大熵筛选(%s)...' %(i, len(rt[i-2]))) pp = [] for j in range(i+2): pp = pp + re.findall('(.)%s(.)' %myre[i], s[j:]) # 取中间一列作为索引 pp = pd.DataFrame(pp).set_index(1).sort_index() # 取交集。排序很重要，可以加快检索速度 index = np.sort(np.intersect1d(rt[i-2], pp.index)) # 左邻与右邻信息熵 index = index[np.array(list(map(lambda s: cal_S(pd.Series(pp[0][s]).value_counts()), index))) &gt; min_s] rt[i-2] = index[np.array(list(map(lambda s: cal_S(pd.Series(pp[2][s]).value_counts()), index))) &gt; min_s] 关于信息熵：熟悉决策树的同学一定不陌生，在这里可理解为词语的自由运用程度。譬如&quot;辈子&quot;，大部分的情况下只会出现&quot;上辈子&quot;，&quot;一辈子&quot;，&quot;几辈子&quot;这种情况，语境自然不丰富，其左邻信息熵相对较小，故&quot;辈子&quot;无法单独成词。原文中的代码如下：12def cal_S(sl): return -( (sl/sl.sum()).apply(log)*sl/sl.sum() ).sum() 最后一步后面只需要我们在原有的词频统计表中，取出满足我们要求的词语出来，并按频数降序排序出即可。 123for i in range(len(rt)): t[i+1] = t[i+1][rt[i]] #只取在rt中出现过的单词 t[i+1] = t[i+1].sort_values(ascending=False) 我们来观测下输出结果 参考资料原文：新词发现的信息熵方法与实现]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[fuzzyset源码解读]]></title>
      <url>%2F2019%2F03%2F06%2Ffuzzyset%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB%2F</url>
      <content type="text"><![CDATA[起因最近懒癌犯的有点长，学了一些东西正好再系统梳理下。 之前需要对大量字符串进行模糊匹配，网上查了查发现fuzzyset第三方库刚好满足我的需求，而且原理简单（核心代码只有100行不到！）。但是由于业务自身需求，需要对源码进行一定的修改，这里记录下对源码的学习，方便自己以后查阅。 背景知识Q： 如何度量两个字符串之间的相似度或者差异程度？Levenshtein距离便是一种方法，又叫编辑距离（Edit Distance），是指两个字符串之间，通过替换、插入、删除的方式（每次仅限编辑一个字符），从一个转换成另一个所需的最小编辑次数。 如将abcd一字转成acdb可以有很多种方法： abcd-&gt;accd-&gt;acdd-&gt;acdbabcd-&gt;acd-&gt;acdb 最小次数显然是第二种，所以从abcd转成acdb的Levenshtein距离就是2，具体如何求解可通过动态规划的思想来完成，这里不深入下去。 fuzzyset算法思想通过n-grams模型把字符串简单拆分，计算两个字符串之间的余弦相似度。若选择use_levenshtein（需要手动安装python-Levenshtein 包），则在余弦相似度的基础上再通过Levenshtein距离计算出一个新的得分，取得分最高的字符串输出（具体细节实现与技巧优化见源码分析） 源码解析1. 切分字符串给定一个英文单词(string)，是如何切分的？作者给了例子说明，比如有个字符串michaelich，我们设置gram_size=3，则切分成如下形式： ‘-mi’‘mic’‘ich’‘cha’‘hae’‘ael’‘eli’‘lic’‘ich’‘ch-‘ 对应代码也容易懂，同时为了节省内存，产生了一个生成器。 1234567def _iterate_grams(value, gram_size=2): simplified = '-' + _non_word_re.sub('', value.lower()) + '-' len_diff = gram_size - len(simplified) if len_diff &gt; 0: simplified += '-' * len_diff for i in range(len(simplified) - gram_size + 1): yield simplified[i:i + gram_size] 接着，作者对每个被切分出来的最小单元进行词频统计(text=&#39;a-CAc9f&#39;)，形式如下： {‘-a’: 1, ‘ac’: 2, ‘ca’: 1, ‘c9’: 1, ‘9f’: 1, ‘f-‘: 1} 代码easy12345def _gram_counter(value, gram_size=2): result = collections.defaultdict(int) for value in _iterate_grams(value, gram_size): result[value] += 1 return result 2. 添加语料库(字符串)当我输入一个英文单词(str)，内部发生了什么？来看代码 1234567891011def __init__(self, iterable=(), gram_size_lower=2, gram_size_upper=3, use_levenshtein=True): self.exact_set = &#123;&#125; self.match_dict = collections.defaultdict(list) self.items = &#123;&#125; self.use_levenshtein = use_levenshtein self.gram_size_lower = gram_size_lower self.gram_size_upper = gram_size_upper for i in range(gram_size_lower, gram_size_upper + 1): self.items[i] = [] for value in iterable: self.add(value) 这里只是初始化，那我们具体看看add()与__add()方法 123456789101112131415161718def add(self, value): lvalue = value.lower() if lvalue in self.exact_set: return False for i in range(self.gram_size_lower, self.gram_size_upper + 1): self.__add(value, i)def __add(self, value, gram_size): lvalue = value.lower() items = self.items[gram_size] #这里要注意：items的改动会传递给 self.items idx = len(items) items.append(0) grams = _gram_counter(lvalue, gram_size) norm = math.sqrt(sum(x**2 for x in grams.values())) for gram, occ in grams.items(): self.match_dict[gram].append((idx, occ)) items[idx] = (norm, lvalue) self.exact_set[lvalue] = value 如果默认n-grams是从2到3的情况下： self.items会存放小写的英文字符串(输入)与对应被2-grams与3-grams切分后的模，形式如下: { 2: [(3.0 , ‘a-cac9f’) , (., .) , (., .)], 3: [(2.449489742783178 , ‘a-cac9f’) , (. , .), (. , .)]} self.match_dict形式如下： { ‘-a’: [(0, 1)], ‘ac’: [(0, 2)], #注意:若之后另一个单词被同样切出’ac’,这里可能为 ‘ac’:[(0,2), (1,1)] ‘ca’: [(0, 1)], ‘c9’: [(0, 1)], ‘9f’: [(0, 1)], ‘f-‘: [(0, 1)], ‘-ac’: [(0, 1)], ‘aca’: [(0, 1)], ‘cac’: [(0, 1)], ‘ac9’: [(0, 1)], ‘c9f’: [(0, 1)], ‘9f-‘: [(0, 1)]} self.exact_set为原输入的英文字符串与小写之后的字符串形式，如： {‘a-cac9f’: ‘a-CAc9f’} 3. 模糊匹配我们来看一下是如何对目标字符串进行模糊匹配的，主要关注__get()方法 1234567891011121314151617181920212223242526272829303132def _distance(str1, str2): distance = Levenshtein.distance(str1, str2) if len(str1) &gt; len(str2): return 1 - float(distance) / len(str1) else: return 1 - float(distance) / len(str2)def __get(self, value, gram_size): lvalue = value.lower() matches = collections.defaultdict(float) grams = _gram_counter(lvalue, gram_size) items = self.items[gram_size] norm = math.sqrt(sum(x**2 for x in grams.values())) for gram, occ in grams.items(): #(切分最小单元，出现次数) for idx, other_occ in self.match_dict.get(gram, ()): #属于第几个输入字符串，出现次数 matches[idx] += occ * other_occ if not matches: return None # cosine similarity results = [(match_score / (norm * items[idx][0]), items[idx][1]) for idx, match_score in matches.items()] results.sort(reverse=True, key=operator.itemgetter(0)) if self.use_levenshtein: results = [(_distance(matched, lvalue), matched) for _, matched in results[:50]] results.sort(reverse=True, key=operator.itemgetter(0)) return [(score, self.exact_set[lval]) for score, lval in results if score == results[0][0]] 先对目标字符串进行同样的切分方式，再分别与每个输入字符串进行“点乘”•，并计算出余弦相似度。 我们看到，若不使用Levenshtein距离，最后输出的是余弦相似度取值最大的一组或多组字符串。若使用Levenshtein距离，首先为了减少运算量，只取余弦相似度排名前50个字符串，再然后对其计算Levenshtein距离，并通过简单的运算得出另一个分值，最后输出得分最高的一组或多组字符串。 后续的源码不难，但还是一并贴出来比较方便看12345678910111213141516def get(self, key, default=None): try: return self[key] # 调用 __getitem__ except KeyError: return defaultdef __getitem__(self, value): lvalue = value.lower() result = self.exact_set.get(lvalue) #若完全一样,返回(1,原词语) if result: return [(1, result)] for i in range(self.gram_size_upper, self.gram_size_lower - 1, -1): results = self.__get(value, i) if results is not None: return results raise KeyError(value) 参考资料 官方github]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[决策树之必知必会]]></title>
      <url>%2F2018%2F05%2F22%2F%E5%86%B3%E7%AD%96%E6%A0%91%E4%B9%8B%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A%2F</url>
      <content type="text"><![CDATA[决策树算法算是一个很经典的算法了，既可以分类，也可以做回归，同时适合集成学习。 什么是决策树一种对样本进行分类的树型结构，也可把它看成if-then规则的集合。 树中的内部节点代表一个属性，该节点引出的分支表示这个属性的全部取值，叶节点表示最终的分类结果。从根节点到叶节点的每条路径便构成if-then的一条规则，且具有互斥且完备的性质，即每一个样本均被且只被一条路径覆盖。 如何学习得到一颗决策树决策树学习本质上是从训练数据上归纳出一种分类规则，使它与训练数据矛盾较小（即能对训练数据正确分类）的同时具有良好的泛化能力。（模型讲完，接下来就是策略与算法） 决策树学习的策略是以损失函数（通常是正则化的极大似然函数）为目标函数的最小化（同其他机器学习模型一致，区别就在于如何优化）。算法则采用启发式算法来近似求解最优化问题，主要分为三步： 特征选择 模型生成 决策树剪枝 具体讲解这三个步骤决策树学习的算法是一个递归地选择最优特征，并根据该特征对训练数据进行分割，使分割后的各个子集有一个最好分类的过程。这一过程就是划分特征空间，构建决策树的过程。 【如何选择最优特征】直观上，如果一个特征具有更好的分类能力，即分割后各个子集中的样本尽可能属于同一类别，那么就更应该选择这个特征。特征分类能力的衡量有信息增益(ID3)、信息增益比(C4.5)、基尼系数(CART)。 【对信息增益、信息增益比、基尼系数的了解】1. 信息增益由熵引申而来。熵是表示随机变量不确定性（无序性）的度量，熵越大，随机变量的不确定性也越大。对于同一枚硬币，当抛正面、抛反面概率相等（概率分布为均匀分布）的情况下，此时不确性定最大，熵也最大。对有相同概率分布的不同随机变量来说，取值越多的随机变量熵越大。 随机变量$X$的熵的表达式如下： H(X) = -\sum\limits_{i=1}^{n}p_i logp_i其中n表示X的n种不同取值，而$p_i$表示X取值为i的概率。 而条件熵是指在已知随机变量$X$的情况下，随机变量$Y$剩下的不确定性。计算方式为：经过X分割过后，各个分支节点的信息熵乘以一个权重的加权求和。这个权重是为了考虑到不同的分支节点所包含的样本数不同，具体公式为： H(Y|X) = \sum\limits_{j=1}^{n}p(x_j)H(Y|x_j)信息增益表示的是：得知特征X的信息而使得分类Y信息的不确定性减少的程度。某个特征的信息增益比较大，就表示该特征分类能力也越大。特征A对数据集D的信息增益为： gain(A) = H(D) - H(D|A)2. 信息增益比用信息增益选择最优划分特征有一个问题：偏向于选择取值较多的特征，这就导致训练出来的树非常宽且深度不深，容易过拟合。所以这里我们使用信息增益比，即把信息增益除以训练集$D$关于特征$A$的熵，公式表示为： Gain\_ratio(D,A)=\frac{g(D,A)}{H_A(D)}3. 基尼系数无论是信息增益还是增益率都涉及到大量的对数运算，为了简化模型与运算量，我们使用基尼系数作为替代。基尼系数表示模型的不纯度，基尼系数越小，则不纯度越低，特征的分类效果就越好。 假设样本$D$有K个类别，第K个类别的概率为$p_k$，则样本$D$的基尼系数为： Gini(D) = \sum\limits_{k=1}^{K} p_k(1-p_k) = 1 - \sum\limits_{k=1}^{K} p_k^2特别的，对于样本$D$，如果根据特征$A$的某个值a，把$D$分成$D1$和$D2$两部分，则在特征$A$的条件下，$D$的基尼系数表达式为： Gini(D,A) = \frac{|D_1|}{|D|}Gini(D_1) + \frac{|D_2|}{|D|}Gini(D_2)【递归的终止条件是什么】主要有3个终止条件： 当前训练子集被正确分类，即全属于同一类别，无需划分 可用特征为空，即特征全部用完 可用特征的信息增益或增益率小于某个阈值$\epsilon$ 【为什么要剪枝，如何剪枝】为防止过拟合，要把过于复杂的树进行剪枝，进行简化。剪枝以极小化决策树整体的损失函数来实现。要注意的是：决策树的生成是学习局部的模型，而决策树剪枝是学习整体的模型。 损失函数如下： C_α(T) = C(T)+α|T|=\sum_{t=1}^{|T|}N_tH_t(T)+α|T|其中，$|T|$ 是树$T$ 的叶节点个数，$t$ 是其中一个叶节点，$N_t$ 是这个叶节点的样本个数，$H_t(T)$ 是这个叶节点的熵，$α|T|$ 表示对模型复杂度的惩罚项（正则化）。 我们再仔细看一看这个损失函数，$C(T)$ 不就是以熵来表示各个叶节点的分类误差（如果某叶节点下的样本属于同一类，那么效果最佳，熵为0），并把所有叶节点的误差相加来表示模型对训练样本的预测误差。 一般剪枝算法给定一个$\alpha$ 后，通过不断剪枝来减小模型的整体损失。具体为： 计算每个节点的熵 递归地从叶节点向上回缩：假设一叶节点在回缩到父节点之前的损失函数值$&gt;=$ 回缩之后的损失函数值，则该剪，即父节点变成新的叶节点 常用的 ID3/C4.5/CART 算法区别在哪里【ID3】 使用信息增益选择最优划分特征，但会遇到问题：通常取值较多的特征信息增益大 未考虑过拟合问题，即没有剪枝 无法处理连续特征，大大限制的ID3的用途 没有考虑到数据缺失的情况 【C4.5】C4.5算法在ID3的基础上改进了上述4个问题。 改进一：使用信息增益比替代信息增益。改进二：引入了正则化系数进行初步的剪枝，防止过拟合改进三：处理连续特征解决思路是连续特征离散化，同时使用二分法。对特征$A$的m个不同取值从小到大排序为$a_1,a_2,…,a_m$, 不妨取每两个相邻节点的均值$T_i=\frac{a_i+a_{i+1}}{2}$作为划分点。对于这（m-1）个点，可像离散属性一样选取最优划分点。注意：若当前节点为连续属性，该属性还可参与后续的子节点产生过程。如先划分属性$A&lt;=10$ ，后续还可继续划分属性$A&lt;=5$。 改进四：处理缺失数据这里需要解决两个问题： 如何在特征缺失的情况下选择划分属性 选定了划分属性之后，如何对样本进行划分 对于问题1，我们对在特征$A$ 上无缺失值的样本计算$A$ 特征对应的信息增益比，最后再乘以一个系数，这个系数是特征$A$ 无缺失的样本所占的比例。 对于问题2，将缺失特征的样本同时划入所有子节点，不过要乘以各个子节点所划入无缺失样本的比例。比如，特征A有3个特征值A1,A2,A3。3个特征值对应的无缺失A特征的样本个数为2,3,4。则缺失特征A的样本a同时划分入A1，A2，A3。对应权重调节为2/9,3/9, 4/9。 C4.5不足的地方： 使用了熵模型，涉及到大量的对数与排序运算，运算强度高 生成的是多叉树。若采用二叉树，可提高计算机运算效率 只能用于分类 剪枝算法有优化空间 【CART】CART算法对C4.5算法的不足做出了改进。主要有CART分类树与CART回归树，下面先讲解分类树。 1. CART分类树的最优特征选择使用基尼系数选择最优特征，二次运算比对数运算简单的多 2. CART分类树对于离散特征处理的改进对离散特征进行二分。如特征$A$有$a1,a2,a3$ 三种类别，ID3与C4.5的做法是建立一个三叉的节点，生成的多叉树。而CART会考虑把$A$分成$\{a1\}$和$\{a2,a3\}$，$\{a2\}$和$\{a1,a3\}$ ，$\{a3\}$和$\{a1,a2\}$这三种情况，找基尼系数最小的组合，比如$\{a1\}$和$\{a2,a3\}$，然后建立二叉树，后续还有机会在子节点上继续选择特征$A$划分$\{a2,a3\}$。 3. CART回归树相比于CART分类树，不同的地方是： 最优特征选择与连续值处理方式不同。对于回归模型，使用平方误差的度量方式，寻找最优特征A与最优切分点s，使得切分过后的数据集D1与D2各自均方差最小，且D1与D2的均方差之和最小，具体为： \underbrace{min}_{A,s}\Bigg[\underbrace{min}_{c_1}\sum\limits_{x_i \in D_1(A,s)}(y_i - c_1)^2 + \underbrace{min}_{c_2}\sum\limits_{x_i \in D_2(A,s)}(y_i - c_2)^2\Bigg]其中c1为D1数据集的样本输出均值，c2为D2数据集的样本输出均值。 最后预测方式不同。分类树是以叶节点里概率最大的类别作为预测类别，而回归树输出的是一个值，采用最终叶节点的均值来预测输出结果。 4. CART树算法的剪枝相比与一般剪枝，其优势在于不用一开始确定$\alpha$值，而是在剪枝的同时找到最优$\alpha$值。剪枝过程主要分两步： 从原始决策树$T_0$底端开始不断剪枝，直到$T_0$的根节点，形成以子树序列$\{T_0,T_1,…,T_n\}$ 通过在独立的验证集上进行交叉验证，从中选出最优子树(同时$\alpha$也是确定下来的) 剪枝思路 【三类算法小结】 算法 支持模型 树结构 特征选择 连续值处理 缺失值处理 ID3 分类 多叉树 信息增益 不支持 不支持 C4.5 分类 多叉树 信息增益比 支持 支持 CART 分类，回归 二叉树 基尼系数，均方差 支持 支持 决策树算法小结不纠结于ID3，C4.5还是CART，从整体上看决策树算法 【优点】 不用数据预处理，不用数据归一化，可以处理缺失数据 可同时处理离散型特征与连续性特征（许多算法两者并不能兼得） 决策树很直观，逻辑上好解释 【缺点】 容易过拟合，通常要设置节点最小样本数、限决策树深度来改进 启发式算法容易陷入局部最优，可通过集成方法改善 复杂的关系，决策树较难学习 参考资料 决策树基础数据挖掘面试题之决策树必知必会知乎：cart树怎么进行剪枝？]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Logistic Regression 模型]]></title>
      <url>%2F2018%2F05%2F01%2FLogistic-Regression-%E6%A8%A1%E5%9E%8B%2F</url>
      <content type="text"><![CDATA[基本原理 找个合适的决策函数即$h$函数（hypothesis），用来预测对输入数据的判断结果。这个过程较为关键，你要对数据有一定的了解或者知道预测函数的“大概”形式，比如线性函数还是非线性函数。 构造损失函数，该函数表示预估的结果（$h$）与实际（$y$）的差异。同时综合考虑所有样本点的“损失”，将Cost求平均，记为$J(\theta)$函数。 通过梯度下降法求$J(\theta)$函数的最小值，使得是预测与真实值之间的偏差达到最小。 求解过程为什么使用Logistic函数现实生活中，二分类问题最常遇到：判断一笔交易是欺诈还是非欺诈；一封邮件是正常邮件还是垃圾邮件等，此时目标变量即类别标签为离散值，通常记作$\{1,0\}$，分别表示正类和负类。而最简单的分类器就是线性分类器，通过找到一个超平面(Hyperplan)，将两个不同的类区分开。对于这个超平面，可以用如下的线性函数表示： w^T+b=0当 $w^T+b&lt;0$ 时，即 $\sum\limits_{i=1}^{n} w_ix_i&lt;-b$ ，此时的样本类别 $y=0$ 当 $w^T+b&gt;0$ 时，即 $\sum\limits_{i=1}^{n} w_ix_i&gt;-b$ ，此时的样本类别 $y=1$ 这不就是我们熟悉的感知机么，即划定一个阈值（-b），通过比较样本与阈值的大小来进行分类。 虽然这个模型简单直观，但存在几个问题。一，假设阈值为10，现在有一个样本进来，最后计算得出10.01，是归为1好还是0好呢？二，这个函数在阈值这个点上不连续，求导很不方便。 因此，逻辑回归引入了Logistic函数，其数学函数是： g(z)=\frac{1}{1+e^{-z}}对应的函数曲线如下图： 通过Logistic函数的图像，发现优点有： 它将线性回归输出的很大范围的数，例如负无穷到正无穷，压缩到(0,1)之间，且远离0的地方函数值会很快接近0/1，这个性质使我们能够以概率的方式来解释 它是一个单调上升函数，具有良好的连续性 ，不存在不连续点 决策函数我们通过Logistic函数，构造了一个预测函数$h$为： h_\theta (x)=g(\theta^{T}x)=\frac{1}{1+e^{-\theta^{T}x}}$h_\theta (x)$函数的值有特殊含义，它表示结果取1的概率。因此对于输入X分类结果为类别1与类别0的概率分别是 P(y=1|x;\theta )=h_\theta(x) P(y=0|x;\theta )=1-h_\theta(x)我们可以把上面两个式子合并成一个，如下： P(y|x;\theta )=h_\theta(x)^{y}(1-h_\theta(x))^{(1-y)}对于Logistic Regression算法来讲，我们需要求解分割超平面中的参数，即权重矩阵$W$与偏置向量$b$。 损失函数我们用极大似然法对参数进行估计，即找到一组参数，使得在这组参数下，数据的似然度越大。假设训练集有$n$个独立的训练样本 \{(x^{(1)},y^{(1)}) ,(x^{(2)},y^{(2)}),...,(x^{(n)},y^{(n)})\}每一个样本被观测到的概率为 P(y=1|x)^{y}(1-P(y=1|x))^{1-y}那么我们的整个样本集，也就是$n$个独立的样本出现的似然函数为 L(\theta)=\prod\limits P(y=1|x)^{y}(1-P(y=1|x))^{1-y}取对数可得到对数似然度 l(\theta)=\sum\limits ylog(h_\theta(x))+(1-y)log(1-h_\theta(x))另一方面，我们更常遇到的是损失函数的概念，主要有0-1损失，log损失等。其中log损失在单个点上的定义为 -log(P(Y|X))=-ylog(p(y|x))-(1-y)(1-log(p(y|x)))若取在整个数据集上的平均log损失，得到 J(\theta)=-\frac{1}{N} l(\theta)即在Logistic Regression中，最大化似然函数与最小化log损失函数是等价的。 损失函数的优化方法Logistic Regression主要使用梯度下降法（Gradient Descent）对损失函数进行优化。它有许多优点，例如只要求解一阶导数，计算成本小，使得能在大规模数据集上应用。它是一种迭代求解的方法，通过在每一步沿着梯度方向，不断调整参数的值来逼近最优值。步骤如下： 选择下降方向即梯度方向 $\nabla {J(\theta)}$ 选择步长，更新参数 $\theta_j = \theta_j - \alpha \frac{\partial}{\partial \theta_j}J(\theta)$ 重复上述步骤，直至满足终止条件 其中损失函数$J(\theta)$在方向 $\theta_j$上的导数为： \frac{\partial{J}}{\partial{\theta_j}} = \frac{1}{n}\sum_{i=1}^{n} (g(\theta^T x^{(i)}) - y^{(i)})x_j^{(i)}或者写成矩阵的形式： \frac{\partial}{\partial\theta}J(\theta) = X^T(h_{\theta}(X) - Y )【矩阵法推导梯度】由于代数法推导过于繁琐，这里我们用矩阵法推导梯度： J(\theta) = -Y\bullet logh_{\theta}(X) - (E-Y)\bullet log(E-h_{\theta}(X))用$J(\theta)$对$\theta$向量求导，得： \frac{\partial}{\partial\theta}J(\theta) = -Y \bullet X^T\frac{1}{h_{\theta}(X)}h_{\theta}(X)(1-h_{\theta}(X)) + (E-Y)\bullet X^T\frac{1}{1-h_{\theta}(X)}h_{\theta}(X)(1-h_{\theta}(X)) \frac{\partial}{\partial\theta}J(\theta) = -Y \bullet X^T(1-h_{\theta}(X)) + (E-Y)\bullet X^T h_{\theta}(X) \frac{\partial}{\partial\theta}J(\theta) = X^T (h_{\theta}(X)-Y )其中，除了矩阵求导的链式法则，我们还用到了下面三个公式： \frac{\partial}{\partial X}logX = 1/X \frac{\partial}{\partial z}g(z) = g(z)(1-g(z)) \frac{\partial}{\partial\theta}X\theta = X^T算法实现这里主要参考的是《机器学习实战》中的代码。 训练样本100条，每一列分别表示$X0、X1、Y$，形式如下：12345678910-0.017612 14.053064 0-1.395634 4.662541 1-0.752157 6.538620 0-1.322371 7.152853 00.423363 11.054677 00.406704 7.067335 10.667394 12.741452 0-2.460150 6.866805 10.569411 9.548755 0-0.026632 10.427743 0 加载代码如下：1234567891011def loadDataSet(): """ 加载数据集 """ dataMat = []; labelMat = [] fr = open('testSet.txt') for line in fr.readlines(): lineArr = line.strip().split() dataMat.append([1.0, float(lineArr[0]), float(lineArr[1])]) #X0设为1.0，构成拓充后的输入向量 labelMat.append(int(lineArr[2])) return dataMat,labelMat 可视化的代码：12345678910111213141516171819202122232425def plotBestFit(weights): """ 画出数据集和逻辑斯谛最佳回归直线 """ import matplotlib.pyplot as plt dataMat,labelMat=loadDataSet() dataArr = array(dataMat) n = shape(dataArr)[0] #行数 xcord1 = []; ycord1 = [] xcord2 = []; ycord2 = [] for i in range(n): if int(labelMat[i])== 1: #标签为1的样本 xcord1.append(dataArr[i,1]); ycord1.append(dataArr[i,2]) else: xcord2.append(dataArr[i,1]); ycord2.append(dataArr[i,2]) fig = plt.figure() ax = fig.add_subplot(111) ax.scatter(xcord1, ycord1, s=30, c='red', marker='s') ax.scatter(xcord2, ycord2, s=30, c='green') if weights is not None: x = arange(-3.0, 3.0, 0.1) y = (-weights[0]-weights[1]*x)/weights[2] #决策边界：令w0*x0 + w1*x1 + w2*x2 = 0，其中x0=1，解出x1和x2的关系 ax.plot(x, y) plt.xlabel('X1'); plt.ylabel('X2'); plt.show() 梯度上升算法12345678910111213141516171819def sigmoid(inX): return 1.0/(1+exp(-inX)) def gradAscent(dataMatIn, classLabels): """ 逻辑斯谛回归梯度上升优化算法 """ dataMatrix = mat(dataMatIn) #转换为 NumPy 矩阵数据类型 labelMat = mat(classLabels).transpose() m,n = shape(dataMatrix) alpha = 0.001 maxCycles = 500 weights = ones((n,1)) for k in range(maxCycles): #最大迭代次数 h = sigmoid(dataMatrix*weights) # 100*3 3*1 --&gt; 100*1 error = (labelMat - h) # sigma (样本点的输出与真实的差异)*该样本点在方向j上的取值 weights += alpha * dataMatrix.transpose() * error #3*100 100*1 --&gt; 3*1 return weights 调用方法：123dataArr, labelMat = loadDataSet()weights = gradAscent(dataArr, labelMat)plotBestFit(weights) 效果示意： 做成动画展现出来123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354def gradAscent(dataMatIn, classLabels, history_weight): dataMatrix = mat(dataMatIn) #转换为 NumPy 矩阵数据类型 labelMat = mat(classLabels).transpose() #转换为 NumPy 矩阵数据类型 m,n = shape(dataMatrix) #矩阵大小 alpha = 0.001 #步长 maxCycles = 500 weights = ones((n,1)) for k in range(maxCycles): #最大迭代次数 h = sigmoid(dataMatrix*weights) #矩阵内积 error = (labelMat - h) #向量减法 weights += alpha * dataMatrix.transpose() * error #矩阵内积 history_weight.append(copy(weights)) return weightsdef draw_line(weights): x = arange(-5.0, 5.0, 0.1) y = (-weights[0]-weights[1]*x)/weights[2] #令w0*x0 + w1*x1 + w2*x2 = 0，其中x0=1，解出x1和x2的关系 line.set_data(x, y) return line, def init(): dataArr = array(dataMat) n = shape(dataArr)[0] xcord1 = []; ycord1 = [] xcord2 = []; ycord2 = [] for i in range(n): if int(labelMat[i])== 1: xcord1.append(dataArr[i,1]); ycord1.append(dataArr[i,2]) else: xcord2.append(dataArr[i,1]); ycord2.append(dataArr[i,2]) ax = fig.add_subplot(111) ax.scatter(xcord1, ycord1, s=30, c='red', marker='s') ax.scatter(xcord2, ycord2, s=30, c='green') plt.xlabel('X1'); plt.ylabel('X2'); return draw_line(ones((n,1))) def animate(i): return draw_line(history_weight[i])# 调用history_weight = []dataMat,labelMat=loadDataSet()gradAscent(dataMat, labelMat, history_weight)fig = plt.figure()currentAxis = plt.gca()ax = fig.add_subplot(111)line, = ax.plot([], [], 'b', lw=2)anim = animation.FuncAnimation(fig, animate, init_func=init, frames=len(history_weight), interval=30, repeat=False,blit=True)plt.show() 可视化 随机梯度上升算法梯度下降法每次更新权值向量$W$是需要遍历所有样本点，计算代价高。而随机梯度下降采用的方法是一次仅用一个样本点数据来计算梯度，从而更新权值向量$W$。 算法：1234567891011121314def stocGradAscent0(dataMatrix, classLabels, history_weight): """ 随机梯度上升算法 """ dataMatrix = array(dataMatrix) m, n = shape(dataMatrix) alpha = 0.01 weights = ones(n) #初始化为单位矩阵 for i in range(m): h = sigmoid(sum(dataMatrix[i]*weights)) #伪随机 error = classLabels[i] - h weights = weights + dataMatrix[i] * alpha * error history_weight.append(copy(weights)) return weights 其中$h$与$error$均为数值，没有矩阵运算。 可视化 虽然每次迭代的复杂度小的多（仅使用一个样本点），但同时使得最后的分类效果不如梯度上升算法，于是我们对随机梯度算法进行改进。 改进随机梯度上升每次迭代式减小步长$\alpha$ ，使算法参数尽可能收敛12345678910111213141516171819def stocGradAscent1(dataMat, classLabels, history_weight, numIter=150): """ 改进的随机梯度上升算法 """ dataMatrix = array(dataMat) m,n = shape(dataMatrix) weights = ones(n) #初始化为单位矩阵 for j in range(numIter): dataIndex = list(range(m)) for i in range(m): alpha = 4/(1.0+j+i)+0.0001 #步长递减，但是由于常数存在，所以不会变成0 randIndex = int(random.uniform(0,len(dataIndex))) #总算是随机了 #print(j,i,randIndex,dataIndex,dataIndex[randIndex]) h = sigmoid(sum(dataMatrix[randIndex]*weights)) error = classLabels[randIndex] - h weights = weights + alpha * error * dataMatrix[randIndex] history_weight.append(copy(weights)) del(dataIndex[randIndex]) #删除这个样本，以后就不会选到了 return weights 可视化 总结优点 形式简单，模型的可解释性非常好。从特征的权重可以看到不同的特征对最后结果的影响。 训练速度较快，资源占用小。分类的时候，计算量仅仅只和特征的数目相关，且内存只需要存储各个维度的特征值。 方便输出结果调整。逻辑回归可以很方便的得到最后的分类结果，因为输出的是每个样本的概率分数，我们可以很容易的对这些概率分数进行cutoff，也就是划分阈值 缺点 形式非常的简单（非常类似线性模型），很难去拟合数据的真实分布。 LR对样本分布敏感，很难处理数据不平衡的问题，所以要注意样本的平衡性（通常需要过采样）。 对于非线性切分，处理比较麻烦。必须在原始数据上做一些非线性变换，比如把X做个平方项，X1*X2等。 逻辑回归本身无法筛选特征。有时候，我们会用gbdt来筛选特征，然后再上逻辑回归。 参考资料 寒小阳 - 机器学习系列(1)_逻辑回归初步美团点评 - Logistic Regression 模型简介logistic回归详解(二）：损失函数（cost function）详解逻辑回归的常见面试点总结]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[统计学习方法（1）- 概论]]></title>
      <url>%2F2018%2F04%2F09%2F%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%EF%BC%881%EF%BC%89-%E6%A6%82%E8%AE%BA%2F</url>
      <content type="text"><![CDATA[统计学习三要素方法 = 模型 + 策略 +算法。当我们想使用统计学习方法对数据进行建模时，首先考虑要用哪种模型建模(如线性模型)；而策略是在给定模型的假设空间下（如线性函数构成的集合），如何选择最优模型（即模型参数的确定）；算法则是指学习模型的具体计算方法（通常解析解不存在）。 策略【损失函数与风险函数】 损失函数：度量模型一次预测的好坏 风险函数：度量平均意义下模型预测的好坏 监督学习问题是在假设空间 $\mathcal{F}$ 中选取模型 $f$ 作为决策函数，对于给定的输入$X$，由$f(X)$给出相应的输出$Y$，这个输出的预测值$f(X)$ 与真实值$Y$可能一致也可能不一致，用一个损失函数来度量预测错误的程度，记作$L(Y,f(X))$。 常用的损失函数有： 0-1损失函数 平方损失函数 绝对损失函数 对数损失函数 【经验风险最小化与结构风险最小化】假设给定一个训练数据集 T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}模型$f(X)$关于训练数据集的平均损失称为经验风险或经验损失，记作${R_{emp}}(f)$: {R_{emp}}(f)=\frac{1}{N}\sum\limits_{i = 1}^N {L({y_i},f({x_i}))}损失函数值越小，模型就越好，而我们学习的目标就是选择期望风险最小的模型。根据大数定律，当样本容量$N$ 趋于无穷时，经验风险趋于期望风险（基于全量）。但由于现实中样本数量有限，预估通常并不理想，要对经验风险进行一定的矫正。 结构风险最小化（structural risk minimization, SRM）是为了防止当样本容量过小产生“过拟合”的解决策略，等价于正则化 ，是在经验风险基础上加上了表示模型复杂度的正则化项，结构风险的定义是： {R_{srm}}(f)=\frac{1}{N}\sum\limits_{i = 1}^N {L({y_i},f({x_i}))}+\lambda J(f)其中$J(f)​$ 表示模型的复杂度，模型$f​$ 越复杂，复杂度$J(f)​$ 就越大，表示了对复杂模型的惩罚。 模型选择在模型选择时，不仅要考虑在训练集上的误差，还要考虑对未知数据的预测能力。如果一味追求在训练数据的预测能力，模型的复杂度往往会比真实模型更高，即产生过拟合。模型选择的方法通常有正则化与交叉验证。这里我们详细的讲一下“交叉验证”。 交叉验证用于给定数据不是很充足的时候，如果样本量相对充足（&gt;1万条），我们一般随机的把数据分成三份，一份训练集（Trainning Set），一份验证集（Validation Set），最后一份测试集（Test Set）。训练集用于训练模型，验证集用于选择模型及其对应的参数，测试集用于最终对学习方法的评估。 【简单交叉验证】首先将样本数据随机分成两部分（70%训练，30%测试），然后用训练集训练模型，在测试集上验证模型与参数。接着，再将模型打乱，重新选择训练集与测试集，继续训练和检验模型。最后用损失函数评估最优的模型与参数。 【S折交叉验证】将样本数据随机分成S个互不相交且大小相同的子集，每次随机的选择S-1份最为训练集，剩下的一份做测试集。将这一过程可能的S种选择重复进行，最后平均误差最小的模型（充分利用了所有样本）。 【留一交叉验证】就是S折交叉验证的特殊情况，S等于样本数N，仅留下1个样本用于测试（即留一），通常用于N小于50的情况下。 最后在Hexo-Next中输入数学公式还是遇到了麻烦，要注意的是：在markdown语法中下划线_代表斜体，而mathjax中的_表示下标，所以使用下标_时，一定要在前面加个反斜杠\_，否则无法解析。 更新（最佳决绝方案，且不用考虑下划线_的问题） 第一步：使用Kramed代替 Marked12npm uninstall hexo-renderer-marked --savenpm install hexo-renderer-kramed --save 第二步：停止使用 hexo-math12npm uninstall hexo-math --savenpm install hexo-renderer-mathjax --save 第三步：更新 Mathjax 的 CDN 链接首先打开/node_modules/hexo-renderer-mathjax/mathjax.html,然后把&lt;script&gt;更改为：1&lt;script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"&gt;&lt;/script&gt; 第四步：更改默认转义规则因为 hexo 默认的转义规则会将一些字符进行转义，所以我们需要对默认的规则进行修改。先找到../node_modules/kramed/lib/rules/inline.js文件，123456789# 把escape: /^\\([\\`*&#123;&#125;\[\]()#$+\-.!_&gt;])/,# 更改为：escape: /^\\([`*\[\]()# +\-.!_&gt;])/,# 再把em: /^\b_((?:__|[\s\S])+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,# 更改为：em: /^\*((?:\*\*|[\s\S])+?)\*(?!\*)/, 第五步：开启mathjax在主题_config.yml中开启Mathjax，即修改如下代码：12mathjax: enable: true 并在博客中开启Mathjax，即添加以下内容：123456---title: Testing Mathjax with Hexocategory: Uncategorizeddate: 2017/05/03mathjax: true--- 详细可参考 如何在 hexo 中支持 Mathjax？ 其余参考资料 如何在Hexo博客中插入数学公式Hexo-NexT主题使用mathjax输入数学公式注意事项hexo在Next主题下输入数学公式]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[读《跃迁-成为高手的技术》]]></title>
      <url>%2F2018%2F01%2F26%2F%E8%AF%BB%E3%80%8A%E8%B7%83%E8%BF%81-%E6%88%90%E4%B8%BA%E9%AB%98%E6%89%8B%E7%9A%84%E6%8A%80%E6%9C%AF%E3%80%8B%2F</url>
      <content type="text"><![CDATA[前言最近在看一些开启心智类的书，想要养成经常思考的习惯。而网上对这本书的评价褒贬不一，但只要自己觉得有收获，那便是学到了。当书中的某些观点能打开你的思路（你甚至会感叹自己怎么就没有意识到），同时结合发生在周边的实例，去验证、补充、反驳，那么你就已经走向勤于思考的道路上了。本书的主旨是讲“如何利用规律与趋势，来放大个人努力，实现跨越式的成长即跃迁”。（图文无关，不过祖峰演的梅贻琦校长气质真的好！） 这个时代都发生了哪些巨大的变化【信息极易获取，外界干扰过多】自己订阅了许多微信公众号，看到别人好的分享总是一键收藏，仔细看过的着实没有几篇，就算是看过的到头来有真正干货的就更少了。信息极易获得的代价就是永远都看不完。同时原本“纯度”很高的信息在为了达到某种目的与利益同时，会进行“再次加工”、“转手”、“掺水”、“偷梁换柱”（比如各类鸡汤与毒鸡汤），读完反而变更迷茫、不知所措，同时浪费了许多时间，抓不到重点。 【跨界竞争，机会变多，成功的概率却变小】你会发现，社会上绝大部分人的工作与职业跟他们在学校学到的东西完全没关系，并且比例越来越大，甚至前几年伴随着移动互联网的普及，人人都想成为产品经理。你的竞争对手会变得越来越多，不在受限于所学的专业了，不终身学习你也许就会被淘汰。 如何改变原有观点，抓住新时代带来的机遇以高优势的状态进入一个高价值的领域，持续迭代，达成“投入与产出的非线性”战略 【找到高价值区域】一个业余爱好者所认为的优势往往在专家眼里并不算优势，场外选手很难判断真正的优势。我们可以有更聪明的做法，从价值而非优势出发。《黑客与画家》中讲了这样一个例子：当一个人在被一条狗追且快要被咬到时，遇到了楼梯口，此时他面临这两种选择，一个是往楼下跑，另一个是往楼上跑。大部分人会选择下楼偷懒省力的方式，而想要不被咬到的最佳选择应该往楼上用更费力的方式跑，这也是大公司与创业公司的区别。同样，高价值的东西因为难、费力，远没有低价值的“小山头”舒服安心，大部分人会因此退却。 不要因为容易做而去做一件事，要因为有价值去做。不要因为便宜而买一件衣服，要因为值得才买。高手总是选择窄门。 【从身边的头部做起】不是所有的高价值区域都适合你，需要结合自身优势，找到属于自己的机会。不要一开始就思考“我怎么成为业内最好的…”、“如何做出一款改变世界的产品”等，因为有可能你既没有见过最好，也没有看到过“业内”。如果你在一个小团队内，那么就先占领团队的头部，然后利用头部优势从小头部走向大头部。 【专注并持续迭代】“全栈工程师”是近几年比较流行的词语，但没有人是真正意义上的“全栈”，因为人的精力是有限的。只有把一个细分领域做深、做好才是你最大的资本与凭仗，并把每次优势不断地迭代与累积，形成你最强大的“护城河”。 如何行动【高效学习】最好以解决问题，有最终输出为目标来学习。也许你会碰到和以前的我一样的问题：无论是背单词还是看书都是从第一页看是看起，结果就一直停留在前几页，到现在买来的书还都放着；看完一本书后没过多久想不起来具体讲了些什么，或者日常生活中的某个概念你记得在书中有提及却无法回忆跟多的细节。这都是由于看过的内容零散分布，东一块西一块，没有建立起框架与内在联系，自然无法回忆起来。而有输出的学习，会倒逼我们去串联各个知识点，形成一个整体或框架以便记忆、提取并运用，这一过程可以形象的比喻成把知识萃取成“知识晶体”。 【系统地看待问题即破局思维】如今的社会是一个复杂的多维系统，无法再用单维、短期的思维方式去解决问题，真实的情况往往更加复杂和反常识，不妨试试以下问题： 让一个地域脱贫的最好方式就一定是给钱么 自己发展不够快，是不是我还要更加努力 敌我公司之间，难道只有你死我亡么 我们再来看两种情况： 兴趣-能力-职业：因为对一件事感兴趣，投入足够多的时间练习，提升了能力，所有兑现了价值；因为有回报，所以更加感兴趣；一个爱好逐渐养成了能力，甚至成为职业。 忙-睡得晚-没精神-效率低(忙)：因为工作多、忙所以每天睡得晚；睡眠时间的少又让你第二天的工作效率低，从而导致你加班完成，变得更忙。 上面就是一正一负两种循环系统。写出来很简单，为什么还是有很多人没意识到？因为它的特点在于短期感受与长期收益相悖。正循环的学习、健康、投入与习惯刚开始都感觉很累，并不舒服，而负循环的开头——忙带来的充实感、工作狂的成就感，短期感受都很好。 所以我们需要识局（系统）的能力，去了解系统，从而进一步搭建正循环系统，破坏负循环系统。那么怎么去了解系统、去破局？ 下层无解，向上一层。对于学习发展而言，若是努力收益不高，就要找方法；方法论太多学不过来，就要重新设目标。所以不要再同一层寻找答案，要向上一层。结合自身的例子就是：为什么身边很多人都高喊我要减肥、运动，但坚持的人少而又少？这个问题并不在“坚持”上，而在于“重不重要”上，在于认知与价值观的问题。因为他们觉得运动还不够重要，而对于足够重要的东西，如吃饭、喝水、睡觉，一天都不会落下。更进一步，究其原因其实就是前面提到过的“短期感受与长期收益相悖”特点。 将眼光放远，要注重无限成长，懂得延迟满足。关于工作：工作不是纯粹为了薪水，而是通过工作积累个人价值，“为了自己做事”。这样就不会计较眼前工资的多与少，也不会有与他人比较时的纠结；关于消费：当你把100元仅用来吃饭，回报就是吃饱，也许和20元没什么两样。但你用20元吃饭，剩余的钱去看一场电影、买一本书、甚至给爱人买一朵玫瑰，那么你的投资非常合算，你收获得了感情、知识、能力上的回报。 写在最后这个时代发展的很快，每个人都被推着加速向前跑，唯恐被抛下。然而人生本身应该是安静的，而非匆忙的。尤其不能被世俗牵着鼻子走，要直面内心的柔软，不放弃对自己的真实，用自己的步伐去丈量这个世界。 最后本周去看了电影《无问西东》，竟有一种无以言语的情感直击胸膛，便以旁白作为结束语。 看到和听到的，经常会令你们沮丧，世俗是这样强大，强大到生不出改变它们的念头来。可是如果有机会提前了解了你们的人生，知道青春也不过只有这些日子，不知你们是否还会在意那些世俗希望你们在意的事情。愿你在被打击时，记起你的珍贵，抵抗恶意；愿你在迷茫时，坚信你的珍贵，爱你所爱，行你所行，听从你心，无问西东。 春天，执子之手，一路同行。 夏天，河边垂钓，静坐听雨。 秋天，落叶归根，层林尽染。 冬天，千里冰封，万里雪飘。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[11月内部建模比赛总结（一）评价风控的标准]]></title>
      <url>%2F2018%2F01%2F10%2F%E5%A6%82%E4%BD%95%E8%AF%84%E4%BB%B7%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BC%98%E5%8A%A3%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
      <content type="text"><![CDATA[前言好几个月都没写点东西，更新博客了。果然，懒惰是人类的天性啊！趁着记忆清晰，对前些日子部门内部的建模比赛进行知识梳理，总结经验与心得，加深印象，以备不时之需。 评价风控（模型）的标准【混淆矩阵】本次建模是关于风控反欺诈，对非金交易客户进行预测，判断是否为欺诈客户。这里暂先撇开风控建模相关的事宜，我们来谈谈评判风控的标准是什么。 最好的风控效果其实是在所有客户中能100%鉴别出欺诈客户，然而现实是：这样的判断力太难实现了。在我们认定欺诈的客户中必然会误杀部分“好”客户；而在认定的非欺诈客户中同样也存在漏网之鱼（欺诈客户）。 因此，这里我们需要引进混淆矩阵这个概念。 (预测) 1 (预测) 0 (真实) 1 TP FN (真实) 0 FP TN 这里的0、1与网上关于混淆矩阵的介绍正好相反。大部分的资料都会把好客户作为把目标客户1，而我们的目标是要预测欺诈客户，所以欺诈客户为1，非欺诈客户为0。通过预测与真实的差异，得到以下4个指标： TP：本身就是欺诈客户，同时也被判断为欺诈客户（True Positive） TN：本身是好客户，同时被判断为好客户（True Negative） FN：欺诈客户被认为是好客户，即漏网之鱼（False Negative） FP：好客户却被判为欺诈客户，即误杀掉的（False Positive） 为了方便记忆这四个单词，可采取如下方法：Positive/Negative指的是预测的结果，如果预测准确，前面加上一个True（真）；预测错了的话就是False（假）。此外，由混淆矩阵又引出了以下两个概念（之后会有用到）： 召回率：简称为TPR，计算公式为TPR=TP/(TP+FN)——所有真实的“1”中，有多少被模型成功选出 误报率：简称为FPR，计算公式为FPR=FP/(FP+TN)——所有真实的“0”中，有多少被模型误判成1 假设现在我们已经有了一个预测模型，得到的是每个客户会发生欺诈的概率，同时画出一个关于欺诈概率的频数分布图，如下： 我们需要一个阈值，来划分欺诈与非欺诈用户。如果为50%，那么概率大于50%的都认为是欺诈用户（再次注意，这里的概率指的是欺诈的概率）；如果阈值调整至70%，原本概率为60%的欺诈客户“张三”，将会被判定为非欺诈。因此，阈值的选取至关重要！ 我们可以把原样本的欺诈/非欺诈客户分开，单独画频数分布图。对于欺诈客户的概率分布，我们给定一个评判的标准（阈值），则左侧灰色部分为FN（欺诈用户漏网了，认为是好人），右侧阴影部分为TP（本身为欺诈，认定为欺诈）。 我们发现，无论阈值标准线往左往右移动，势必会导致TP(被正确判断的欺诈用户)与TN（被正确判断的非欺诈用户）一方增大与一方减小。这样也正解释了风控力度的大小。阈值标准线越往左，风险控制越苛刻，漏网之鱼（FN）就越小，但与此同时非欺诈客户量（TN）也越小，原本正常的客户被误判为欺诈（FP）的也越多。 【ROC与AUC】那么阈值究竟这么取比较好呢？这其实是个很有考量的技术活。还记得我们之前提及的召回率（TPR）与误报率（FPR）么。在给定TPR的情况下，FPR越小，说明误判的“好人”越少；同理，在给定FPR（能接受一定好人误判的）的情况下，如果TPR越大，说明抓出来的“坏人”也越多。 假如阈值取0.6，我们把大于0.6的标记为1（违约），小于0.6的标记为0（正常），同时可以计算出TPR与FPR。同理，如果阈值换成了0.5，我们又得到一组（TPR2，FPR2）。于是，我们以FPR为横坐标，TPR为纵坐标，把不同的点连成一条曲线，就是ROC曲线。 其实TPR与FPR是正相关的，也就是说：正确判断出“1”的数量增加，必然会付出代价（误判为“1”的FP也会增加）,ROC曲线上也能反映出这种变化趋势，从△TPR&gt;△FPR到△TPR&lt;△FPR。所以这里就回答了我们之前提出的问题：理想的阈值应该取△TPR=△FPR时所对应的阈值。 当我们有2个模型，画出了两条ROC曲线时，可以利用ROC曲线下的面积，即AUC或者C-统计量，来判断模型的效果。AUC越高，说明模型的分辨效果越好。 【提升图与洛伦兹曲线】除了ROC曲线与AUC指标，常用的模型评价还有K-S曲线，而K-S曲线又是由洛伦兹曲线变换之后得到，所以这里我们结合《信用风险评分卡》书中的例子来介绍相关概念。 假设10000笔借款，实际发生了700笔坏账。如果我们把10000笔随机分成10等分，那么每等分的坏账应该为70笔。 再假设我们有一个模型。通过这个模型，我们能给出每笔借款可能发生坏账的概率，将概率从高到低排序。排名越靠前的，发生坏账的可能性越大。我们对排好序的序列也分成10等分。那么应该是，越靠前的等份里，包含的坏人应该越多，越靠后的等份里，包含的坏人要更少（好人更多）。一个理想的模型，应该是这个排序与真实的排序是一样的，即，从一个分割点开始，靠前的都是坏人，靠后的都是好人。 理想是美好的，然而现实是残酷的，我们总会误杀好人，也会漏掉坏人，能做的是把更多的坏人排到越前面。回到“提升图”相关内容，我们对之前排好序且10等份的数据计算各自等份内的违约数、占比与累计占比，如图： 把每份违约占比（实际与随机即第4与第7列）放到一张柱形图上，即提升图。 也可以将累计占比（实际与随机即第5与第8列）放到一张曲线上，即洛伦兹曲线。 有了洛伦兹曲线，我们就可以直观的比较两个模型的优劣了。我们在一张图上画上两个模型的洛伦兹曲线A与B，假定用户群体中真实的欺诈率是40%（即理想的模型中所有的违约用户全部集中在前4个等份）。我们可以看到，模型A识别出88%的违约用户，而B模型只能分离出78%的用户，所以模型A要比模型B效果好。所以以后我们只要看哪个模型越往“左上角鼓”，效果就越好。 【K-S曲线】现在我们对“好人”，“坏人”分别画洛伦兹曲线，这两条曲线的差值，就是K-S曲线。如下图所示，假定我们选取阈值为20%（即认定概率大于20%的用户为违约用户），则该模型可以挑选出60%的违约用户，但同时会误判8%的“好人”。那么K-S曲线在违约率上的值就是60%-8%=52%。 K-S曲线主要是验证模型的区分能力，曲线中的最大值就是K-S统计量。K-S统计量越大，就越能把“好”“坏”区分开来，模型效果也就越好。 我们再深入一层，针对60%与8%这两个数字细想一下：这60%不正是在设定20%阈值情况下，TPR的定义么。同理，8%对应着FPR。所以K-S曲线实际上就是以10%*k为横坐标，分别以TPR与FPR的值为纵坐标画出的两条曲线的差值。而KS=max(TPR-FPR)即两条曲线的最大差值，当KS最大时，也就是△TPR=△FPR，这不就是我们之前在ROC曲线上找到的最优阈值么？所以无论是ROC曲线还是K-S曲线，其本质上是一样的。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[朴素贝叶斯-新闻文本分类]]></title>
      <url>%2F2017%2F09%2F09%2F%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E2%80%94-%E6%96%B0%E9%97%BB%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%2F</url>
      <content type="text"><![CDATA[「朴素贝叶斯」具体理论就不详细讲解了，网上一搜一大把。其核心思想就是： 朴素贝叶斯 = 条件独立假设 + 贝叶斯方法。运行速度快，在满足分布独立这一假设条件下分类效果好，但对于训练集中没有出现过的词语要平滑处理，数值型变量特征默认符合正态分布。 「Python实现」导入停用词导入停用词库，同时使用strip()方法剔除不需要的空白符，包括（&#39;\n&#39;, &#39;\r&#39;, &#39;\t&#39;, &#39; &#39;）12345678def make_word_set(words_file): words_set = set() with codecs.open(words_file,'r','utf-8') as fp: for line in fp: word = line.strip() if len(word) &gt; 0 and word not in words_set: words_set.add(word) return words_set 文本处理，样本生成每个新闻文本txt文件在各自所属类别的文件夹中，结构如下： “folder_path” ｜ ｜－－ C000008 －－ 1.txt / 2.txt / … / 19.txt ｜－－ C000010 ｜－－ C000013 ｜－－ … ｜－－ C000024 这里使用os.listdir()读取指定目录下的所有文件夹名（即分类类别），遍历各自文件夹（类别）内的文本文件，对每一个txt文件进行文本切词，同时利用zip()函数使每个新闻文本与所属类别一一对应，一共有90条数据。 为了随机抽取训练与测试数据集，用random.shuffle()打乱顺序，并选取20%的数据用于测试，同时把特征数据与类别数据各自分开。 最后对训练数据集中的词语进行词频统计。这里有使用sorted()函数进行排序，方法为sorted(iterable, cmp = None, key = None, reverse = False)，其中参数含义如下： iterable：是可迭代类型（我这里的可迭代类型为字典） cmp：用于比较的函数，比较什么由key决定（这里没用到） key：用列表元素的某个属性或函数进行作为关键字（这里使用字典中的“值”大小作为关键字排序） reverse：排序规则，True为降序（False为升序） 12345678910111213141516171819202122232425262728293031323334353637383940414243def text_processing(folder_path, test_size = 0.2): folder_list = os.listdir(folder_path) data_list = [] class_list = [] # 遍历文件夹 for folder in folder_list: new_folder_path = os.path.join(folder_path,folder) files = os.listdir(new_folder_path) j = 1 for file in files: if j &gt; 100: # 防止内存爆掉 break with codecs.open(os.path.join(new_folder_path, file), 'r', 'utf-8') as fp: raw = fp.read() word_cut = jieba.cut(raw, cut_all = False) word_list = list(word_cut) data_list.append(word_list) # 训练集 class_list.append(folder) # 类别 j += 1 # 划分训练集和测试集 data_class_list = list(zip(data_list, class_list)) random.shuffle(data_class_list) # 打乱顺序 index = int(len(data_class_list) * test_size) + 1 # 抽取测试数据集的占比 train_list = data_class_list[index:] test_list = data_class_list[:index] train_data_list,train_class_list = zip(*train_list) # 特征与标签 test_data_list,test_class_list = zip(*test_list) # 统计词频 all_words_dict = &#123;&#125; for word_list in train_data_list: for word in word_list: if word in all_words_dict: all_words_dict[word] += 1 else: all_words_dict[word] = 1 # 降序排序（key函数） all_words_tuple_list = sorted(all_words_dict.items(),key = lambda f:f[1], reverse = True) all_words_list = list(zip(*all_words_tuple_list))[0] return all_words_list, train_data_list, test_data_list, train_class_list, test_class_list 特征选择这里我们仅选取词频坐高的1000个特征词（维度），并剔除数字与停用词。12345678910def words_dict(all_words_list,deleteN,stopwords_set=set()): feature_words = [] n = 1 for t in range(deleteN,len(all_words_list),1): if n &gt; 1000: # 最多取1000个维度 break if not all_words_list[t].isdigit() and all_words_list[t] not in stopwords_set and 1 &lt; len(all_words_list[t]) &lt; 5: feature_words.append(all_words_list[t]) n += 1 return feature_words 用选取的特征词构建0-1矩阵对训练数据集train_data_list中每篇切完词之后的文档构建特征向量（由上述1000个特征词组成），若出现则取值为1，否则为0。于是90篇文章构建出了[90,1000]维度的0-1矩阵（其中71行为训练数据，19行为测试数据）。 训练集如下： 0-1矩阵如下： 1234567891011def text_features(train_data_list, test_data_list, feature_words): def text_features(text,feature_words): # text = train_data_list[0] text_words = set(text) features = [1 if word in text_words else 0 for word in feature_words] return features # 0,1的矩阵（1000列-维度） train_feature_list = [text_features(text, feature_words) for text in train_data_list] test_feature_list = [text_features(text, feature_words) for text in test_data_list] return train_feature_list,test_feature_list 朴素贝叶斯分类器这里使用开源sklearn库中的朴素贝叶斯分类器，输入参数分别为训练集的0-1特征矩阵（train_feature_list）与训练集分类（train_class_list），然后对测试数据的输出与真实结果进行比较，得到准确度为0.68 12345def text_classifier(train_feature_list,test_feature_list,train_class_list,test_class_list): # sklearn多项式分类器 classifier = MultinomialNB().fit(train_feature_list,train_class_list) # 特征向量与类别 test_accuracy = classifier.score(test_feature_list,test_class_list) return test_accuracy 这里我们仅选取词频最高的1000个作为特征向量，不妨尝试下选取其他的关键字作为特征向量，发现准确率都在0.63以上，分类效果还算可以，见下图： 12345678910111213141516171819202122232425262728293031if __name__ == '__main__': # 文本预处理（分词、划分训练与测试集、排序） folder_path = '...' all_words_list, train_data_list, test_data_list, train_class_list, test_class_list = text_processing(folder_path, test_size = 0.2) # stopwords_set stopwords_file = '...' stopwords_set = make_word_set(stopwords_file) # 特征提取与分类 deleteNs = range(0,1000,20) test_accuracy_list = [] for deleteN in deleteNs: # 选取1000个特征 feature_words = words_dict(all_words_list,deleteN,stopwords_set) # 计算特征向量 train_feature_list, test_feature_list = text_features(train_data_list,test_data_list,feature_words) # sklearn分类器计算准确度 test_accuracy = text_classifier(train_feature_list,test_feature_list,train_class_list,test_class_list) # 不同特征向量下的准确度 test_accuracy_list.append(test_accuracy) print(test_accuracy_list) # 结果评价 plt.figure() plt.plot(deleteNs,test_accuracy_list) plt.title('Relationship of deleteNs and test_accuracy') plt.xlabel('deleteNs') plt.ylabel('test_accuracy') plt.savefig('result.png',dpi = 100) plt.show() 「参考资料」 用朴素贝叶斯进行文本分类朴素贝叶斯分类器的应用]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[《小岛经济学》读书笔记（四）]]></title>
      <url>%2F2017%2F08%2F26%2F%E3%80%8A%E5%B0%8F%E5%B2%9B%E7%BB%8F%E6%B5%8E%E5%AD%A6%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89%2F</url>
      <content type="text"><![CDATA[量化宽松其本质是向金融市场注入新的资金，来推动价格上涨。实际上，就是通货膨胀的委婉说法，是将政府债务货币化的隐秘手段。文中作者把它比喻成用汽油去救火，汽油越多，火势也就越大。如果不知道汽油是可燃物，我们也许会得出这样的结论：火没有被扑灭是因为汽油的量还不够大。 总结与启示作者对于经济的核心思想：需求才是促进经济增长的真正动力，而非消费。增大货币量固然会鼓励人们消费，但对扩大需求毫无裨益。 构建属于自己的捕鱼器并不断优化资本（工具）的产生提高了产出与效率，让你有更多的储蓄与时间做更有创造力的事情。对于我们自身，应该建立自己的专业性与知识体系，而非像徒手捕鱼的渔民，陷入低产出的工作中。 重视储蓄的价值了解自身的收入与支出，合理并结构化自己的支出与储蓄比例。但是有的消费却不能省，如孝顺父母的钱，对自己的投资（ROI是最大的）。 了解市场/行业的供需关系你的价值是根据市场需求来决定的。符合市场需求并且稀缺，那么你的价值就越大。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[《小岛经济学》读书笔记（三）]]></title>
      <url>%2F2017%2F07%2F31%2F%E3%80%8A%E5%B0%8F%E5%B2%9B%E7%BB%8F%E6%B5%8E%E5%AD%A6%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89%2F</url>
      <content type="text"><![CDATA[第七~十一章自由贸易的优势扩大的选择范围（进口的T恤比本土要便宜），可以让美国人花更少的钱在T恤上。而省下来的钱可用于生产其他东西，这对于那些能输送最有价值产品的公司也是有利的。 由于本土的（T恤）企业无法找到竞争优势，工人会下岗。但经济的目的并非提供就业岗位，而是不断提高生产力。浪费劳动力制造那些国外生产率更高的产品是毫无意义的，应该找到自己更具优势的行业（更擅长制造的产品）。 关于美联储1913年，美联储成立，发行纸币，并承诺持有者可以随时兑换黄金。其最初目的是“弹性货币供应”：根据经济活动的情况，扩大或收紧货币的流通量，从而让物价保持平稳，不收繁荣或萧条的影响。 然而过去的100年里，物价上涨、货币的贬值（货币购买力下降），美元损失了超过95%的价值。美国人手里仅持有一种没有实际价值且可以随意增发的货币。 通货膨胀岛上捕鱼的增长率远低于发行纸币的增长率，于是“通鱼膨胀”的难题产生了，物价上涨。 很多人认为物价上涨就是通货膨胀，其实不然，上涨的价格只是通货膨胀的结果罢了。通货膨胀其实就是货币供应量增加，货币紧缩就是货币供应量收紧。 政府面对经济衰退的本能反应是造更多的纸币，因为经济学家认为物价下跌会导致经济陷入需求崩溃的万丈深渊。但事实是，物价需要下跌才能平衡正在衰退的经济局势。当经济不景气时，人们会停止消费，物价下跌。当跌到一定程度，人们又会开始消费。整个过程淘汰了不必要的产能，并把物价调整到了符合内在供求关系的水平。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[《小岛经济学》读书笔记（二）]]></title>
      <url>%2F2017%2F07%2F26%2F%E3%80%8A%E5%B0%8F%E5%B2%9B%E7%BB%8F%E6%B5%8E%E5%AD%A6%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
      <content type="text"><![CDATA[第五、六章生产效率由于生产效率的提升（储蓄、创新与投资的结果），产品的价格也随之下降，于是更多的顾客可以去消费购买，昔日的奢侈品也成了普通消费品。 工作与薪资由于岛上经济的多样化与社会分工的加剧，大多数劳动者会选择为别人工作（就业），用劳动换取报酬（薪资）。那么如何衡量劳动者的劳动价值？ 需求 供应 生产效率 所以想要获得较高的薪资，必须要提高自身价值，要么掌握稀缺的能力，要么通过刻意练习提高工作效率与熟练度。 利率政府不但可以通过政策的倾向性扰乱信贷市场，还可以通过操控利率影响信贷市场。政府被授予这一权利的背后是为了保证经济的平稳运行（无论是繁荣还是萧条期）。其理论基础是：美联储的经济学家能运用集体智慧，推算出特定时点最理想的利率水平，从而使经济正常运行。 但这一机制有两个致命的缺陷： 美联储与利率没有任何关系，既不产生储蓄，也不为坏账而蒙受损失。没有这种关联，真的能比市场更清楚什么事恰当的利率水平么？ 美联储的决定基于政治考量多于经济因素。因为低利率能让经济表面上表现更好。但事实是，过低的利率会传达出错误的信号，误以为经济状态良好、投资可行。结果就是虚假的繁荣之后出现巨大的危机。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[《小岛经济学》读书笔记（一）]]></title>
      <url>%2F2017%2F07%2F24%2F%E3%80%8A%E5%B0%8F%E5%B2%9B%E7%BB%8F%E6%B5%8E%E5%AD%A6%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
      <content type="text"><![CDATA[第一、二章：工具的出现改变了一切关于资本与储蓄资本（设备）的建设与使用本身并没有什么意义，价值在于利用资本制造所需之物。同时带来的是生产力的提高，从而获得储蓄与积累（剩余价值）。 关于经济最基本的定义：努力使有限的资源来产生最大的效益，尽可能满足人类的需求。工具、资本、创新是实现这一目标的关键。 经济增长的原因：找到了生产人类所需物品的更好方式。 关于财富财富从来就是一个相对的概念。有人认为现在的贫富差距越来越大，但我们也要同时看到好的一面。整个社会的财富在变多，以前只有富人才能坐的起马车，现在基本人人都有能力买车，唯一区别在于品牌。即便是在中世纪最至高无上的国王眼里也是缺乏的各类娱乐设施，在如今的社会几乎人人都能享受。 富人真正致富的原因是为他人提供有价值的东西并承担一定的风险，文中艾伯不工作获得的利润是对他出借储蓄（鱼）所承风险的补偿（不还鱼）。 总结成一句话工具提高生产力，生产力提高了，获得剩余价值，剩余价值引发借贷，借贷产生经济，经济发展促进财富积累。 第三、四章：该不该存钱？积累储蓄的重要性 提高个人的消费能力，实现人生更多可能的方式，比如所走就走的一场旅行。 防止经济受到意外因素的缓冲器。 消费与储蓄消费是只是用来衡量生产的尺度，因为生产的最终目的是消费。为了消费而消费并不会推动经济增长，就如花了100万买了一堆空气（并不是你真正需要的），虽然这100万算进了GDP中(同时表明不能仅用GDP来衡量经济是否增长)。必须要生产出有价值的东西（人们需要的），才能使消费有价值，经济才能增长。 然而储蓄创造了资本，资本使生产扩大成为了可能。所以从某种意义上，储蓄起来的一美元对经济产生的积极影响要大于消费掉的一美元。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[天姥徒步行]]></title>
      <url>%2F2017%2F05%2F30%2F%E5%A4%A9%E5%A7%A5%E5%BE%92%E6%AD%A5%E8%A1%8C%2F</url>
      <content type="text"><![CDATA[「序」海客谈瀛洲，烟涛微茫信难求。越人语天姥，云霞明灭或可睹…… 这首太白诗中的天姥山便是我们此行的目的地。 「随便说些什么」四个小伙伴跟随着稻草人的步伐，来了次虐身的登山~~~（谁让我们平时没怎么锻炼） #Day 1解决了午饭，顺利抵达山脚，开始此次登山之旅。 上山走累了，便随地憩息。清泉真的好冰凉，直接饮用也无碍。 沿途的风景让人回归自然，心情舒畅，一片盎然生机的景象。 感觉就如李太白所说“身登青云梯”这种感觉 晚上的“狼人杀”欢乐多多，尤其是我左右两边的女巫与预言家，你们要给力、好好带队啊~ 看着浩瀚的星空，渐渐入睡…… #Day 2第二天早上补充能量之后，开始了崎岖的下山之旅。 你在桥上看风景，看风景的人在楼上看你。 明月装饰了你的窗， 而你装饰了别人的梦。 爱笑的女生运气总不会太差 游览沃洲湖 这一刻的定焦，希望能保持永远永远 最后放上笑得有点傻傻、永远18岁的giver! 「后记」恰同学少年，风华正茂，书生意气，挥斥方遒。指点江山，激扬文字，粪土当年万户侯。愿我们始终怀有一颗赤子之心。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[D3学习系列（三） 桑基图]]></title>
      <url>%2F2017%2F04%2F15%2FD3%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%89%EF%BC%89-%E6%A1%91%E5%9F%BA%E5%9B%BE%2F</url>
      <content type="text"><![CDATA[「前言」网上关于桑基图的例子也有一些，但是对于初入门的新手并不友好、易懂。如果仅用百度搜索，资料更是少得可怜（这里感谢同事推荐shadowsocks进行科学上网●^●）。当然有些语句没有看懂，anyway先实现了再说~ 「什么是桑基图」桑基图（Sankey diagram），即桑基能量分流图，主要是用来描述能量、人口、经济等的流动情况。因1898年Matthew Henry Phineas Riall Sankey绘制的“蒸汽机的能源效率图”而闻名，此后便以其名字命名为“桑基图”。 桑基图主要关注能量、物料或资本等在系统内部的流动和转移情况。Sankey diagram的特点有： 起始流量和结束流量相同 在内部，不同的线条代表了不同的流量分流情况，它的宽度成比例地显示此分支占有的流量 节点不同的宽度代表了特定状态下的流量大小 在数据可视化中，桑基图有利于展现分类维度间的相关性，以流的形式呈现共享同一类别的元素数量。特别适合表达集群的发展，比如展示特定群体的人数分布等。我们可以欣赏下利用桑基图展示的可视化作品，太美了简直！ 「绘制桑基图」绘制画布SVG123456789101112131415var margin = &#123;top: 1, right: 1, bottom: 6, left: 1&#125;, width = 1000 - margin.left - margin.right, height = 650 - margin.top - margin.bottom;var formatNumber = d3.format(",.0f"), // 数字转字符串 逗号分隔，0位小数点 format = function(d) &#123;return formatNumber(d) + "m CHF";&#125;;var color = d3.scale.category20();var svg = d3.select("#chart")//ID选择器 .append("svg") .attr("width", width + margin.left + margin.right) .attr("height", height + margin.top + margin.bottom) .append("g") .attr("transform", "translate(" + margin.left + "," + margin.top + ")"); 在body中定义一个&lt;p&gt;元素，令id=&quot;chart&quot;，画布SVG作用在元素&lt;p&gt;中，保持有一定的margin。 定义桑基布局123456var sankey = d3.sankey() .nodeWidth(25) // 节点宽度 .nodePadding(20) // 矩形垂直方向的间距 .size([width,height]);var path = sankey.link(); sankey.link()函数应该是插件sankey.js中定义好的，目的是生成节点相对应的路径。 绑定数据123456d3.json("http://benlogan1981.github.io/VerticalSankey/data/ubs.json", function(error, energy) &#123; sankey .nodes(energy.nodes) // 绑定节点数据 .links(energy.links) // 绑定路径数据 .layout(32); // iterations ?&#125;; 这里我们通过引用外部JS数据的方式来绑定，之后直接使用energy.的方式调用，方式如下：d3.json(&quot;XXX.json&quot;, function(error, energy) {}; 注意如果不启动外部服务器，是没有办法加载外部数据的。由于Python自带的包可以建立简单的Web服务器，便直接用Python： 命令行中直接CD到准备做服务器的根目录下，输入命令：python -m SimpleHTTPServer 8080（这里使用的2.X版本，3.X版本稍有不同） 然后就可以在浏览器中输入：http://localhost:8080/路径来访问服务器的资源 JSON数据这里的JSON数据长这样： {“nodes”:[{“name”:”Wealth Management”},{“name”:”WMA”},…{“name”:”Switzerland”}],“links”:[{“source”:0,”target”:5,”value”:100},{“source”:1,”target”:5,”value”:1800},….{“source”:4,”target”:8,”value”:400}]} nodes表示节点数据；links表示连线数据，其中source为起始节点，target表示终点节点，value为量的大小。关于.layout()，查了相关资料，好像是跟计算出来的节点与路径数据的迭代次数（iterations）有关，但是调整参数值并没有发现什么变化。 绘制路径数据links123456789101112131415161718192021var link = svg.append("g").selectAll("path") .data(energy.links) .enter() .append("path") .attr("class","link") .attr("d",path) // 路径链接已被sankey封装好 .style("stroke-width",function(d)&#123; return Math.max(1,d.dy); &#125;) .style("stroke",function(d) &#123; return d.source.color = color(d.source.name.replace(/ .*/,"")); &#125;) .sort(function(a,b)&#123; return b.dy - a.dy; &#125;) ;link.append("title") .text(function(d)&#123; return d.source.name + "-&gt;" + d.target.name + "\n" + format(d.value) ; &#125;); stroke-width参数表示links的宽度，返回的是1和dy中的最大值，但大部分情况都会返回dy。如果换成10（这样每根连线都是一样宽度），看一下效果就知道stroke-width的作用了： stroke其实是描边的意思，感觉由于header部分设置过了fill：none，所以才默认为填充的颜色。这里设置相同起始节点的连线具有相同的颜色，确保达到你想要颜色分类的效果。同时对每条links添加title，鼠标悬停会显示相应内容。 绘制节点数据nodes123456789101112131415161718192021222324252627282930313233343536var node = svg.append("g").selectAll("g") .data(energy.nodes) .enter() .append("g") .attr('class', "node") .attr('transform', function(d)&#123; return "translate(" + d.x + "," + d.y + ")"; //节点的(x,y)坐标 &#125;);node.append("rect") .attr("height",sankey.nodeWidth()) .attr("width",function(d) &#123; return d.dy; &#125;) .style("fill",function(d) &#123; return d.color = color(d.name.replace(/ .*/, "")); &#125;) .style("stroke",function(d) &#123; return d3.rgb(d.color).darker(2); &#125;) .append("title") .text(function(d) &#123; return d.name + "\n" + format(d.value) ; &#125;);node.append("text") .attr("text-anchor","middle") .attr("x",function(d) &#123; return d.dy/2; &#125;) .attr("y",function(d) &#123; sankey.nodeWidth() / 2; &#125;) .attr("dy","1em") .text(function(d) &#123; return d.name; &#125;) .filter(function(d) &#123; return d.x &lt; width / 2 ; &#125;); 每个rect元素的高度(height)相同，宽度(width)为相应的dy；stroke把外框颜色设置成与rect元素同样的颜色并加深，图片放大可以明显的看出效果），.text添加鼠标悬停显示相应文字，效果如下： 添加交互效果1.用CSS控制悬浮样式，让连接线在鼠标悬停的时候高亮显示：12345&lt;style &gt; .link:hover &#123; stroke-opacity: .8; &#125;&lt;/style&gt; 2.节点添加拖动事件 定义一个拖动事件，这里仅限于水平方向的移动，移动之后重新布局并生成行的路径 1234567function dragmove(d) &#123; d3.select(this) .attr("transform","translate(" + (d.x = Math.max(0,Math.min(width - d.dy, d3.event.x))) + "," + d.y + ")") ; sankey.relayout(); // 重新布局 link.attr("d",path);&#125; 对node节点添加事件 123456789node.call(d3.behavior.drag() //这一段只知道大概是什么意思 .origin(function(d)&#123; return d; &#125;) .on("dragstart",function() &#123; this.parentNode.appendChild(this); &#125;) .on("drag",dragmove) ); 好了，现在我们就可以做出首页第一张sankey图的效果了，最后再附上自己做的另一张横版sankey图（好像是由于sankey.js插件的问题，导致横竖排版） 源代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;&lt;/title&gt; &lt;script src="js/d3.js" charset="utf-8"&gt;&lt;/script&gt; &lt;script src="js/d3-sankey-1.js" charset="utf-8"&gt;&lt;/script&gt; &lt;style &gt; body &#123; background-color: white; &#125; #chart &#123; height: 650px; /* must at least match the svg, to place content after it!*/ &#125; .node rect &#123; cursor: move; fill-opacity: .9; shape-rendering: crispEdges; &#125; .node text &#123; pointer-events: none; text-shadow: 0 1px 0 #fff; &#125; .link &#123; fill: none; /*stroke: #000;*/ stroke-opacity: .5; &#125; .link:hover &#123; stroke-opacity: .8; &#125; &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;p id="chart"&gt;&lt;/p&gt; &lt;script&gt; var margin = &#123;top: 1, right: 1, bottom: 6, left: 1&#125;, width = 1000 - margin.left - margin.right, height = 650 - margin.top - margin.bottom; var formatNumber = d3.format(",.0f"), // 数字转字符串 逗号分隔，0位小数点 format = function(d) &#123;return formatNumber(d) + "m CHF";&#125;; var color = d3.scale.category20(); var svg = d3.select("#chart")//ID选择器 .append("svg") .attr("width", width + margin.left + margin.right) .attr("height", height + margin.top + margin.bottom) .append("g") .attr("transform", "translate(" + margin.left + "," + margin.top + ")") ; // 布局 var sankey = d3.sankey() .nodeWidth(25) // 节点宽度 .nodePadding(20) // 矩形垂直方向的间距 .size([width,height]) // .nodes(data.nodes) // .links(data.links) // .layout(3) ; var path = sankey.link(); console.log(path); d3.json("http://benlogan1981.github.io/VerticalSankey/data/ubs.json", function(error, energy) &#123; sankey .nodes(energy.nodes) .links(energy.links) .layout(32); var link = svg.append("g").selectAll("path") .data(energy.links) .enter() .append("path") .attr("class","link") .attr("d",path) // 路径链接已被sankey封装好 .style("stroke-width",function(d)&#123; return Math.max(1,d.dy); &#125;) // .style("stroke",function(d) &#123; // console.log(d.source.name.replace(/ .*/,"")); // &#125;) .style("stroke",function(d) &#123; return d.source.color = color(d.source.name.replace(/ .*/,"")); &#125;) .sort(function(a,b)&#123; return b.dy - a.dy; &#125;) ; link.append("title") .text(function(d)&#123; return d.source.name + "-&gt;" + d.target.name + "\n" + format(d.value) ; &#125;); var node = svg.append("g").selectAll("g") .data(energy.nodes) .enter() .append("g") .attr('class', "node") .attr('transform', function(d)&#123; return "translate(" + d.x + "," + d.y + ")"; &#125;) .call(d3.behavior.drag() .origin(function(d)&#123; return d; &#125;) .on("dragstart",function() &#123; this.parentNode.appendChild(this); &#125;) .on("drag",dragmove) ) ; node.append("rect") .attr("height",sankey.nodeWidth()) .attr("width",function(d) &#123; return d.dy; &#125;) .style("fill",function(d) &#123; return d.color = color(d.name.replace(/ .*/, "")); &#125;) .style("stroke",function(d) &#123; return d3.rgb(d.color).darker(2); &#125;) .append("title") .text(function(d) &#123; return d.name + "\n" + format(d.value) ; &#125;) ; node.append("text") .attr("text-anchor","middle") .attr("x",function(d) &#123; return d.dy/2; &#125;) .attr("y",function(d) &#123; sankey.nodeWidth() / 2; &#125;) .attr("dy","1em") .text(function(d) &#123; return d.name; &#125;) .filter(function(d) &#123; return d.x &lt; width / 2 ; &#125;) ; function dragmove(d) &#123; d3.select(this).attr("transform","translate(" + (d.x = Math.max(0,Math.min(width - d.dy, d3.event.x))) + "," + d.y + ")") ; sankey.relayout(); link.attr("d",path); &#125; &#125;); &lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 「参考资料」 【D3 Tips and Tricks v4.x】【D3.js数据可视化实战】—（3）桑基图（sankey）的绘制【USB 2015 Q1 Results】]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[《大数据与机器学习》读书笔记（二） 应用篇]]></title>
      <url>%2F2017%2F04%2F07%2F%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89-%E5%BA%94%E7%94%A8%E7%AF%87%2F</url>
      <content type="text"><![CDATA[标签系统 - “空间换时间”作用与意义 避免重复计算，提高查询效率 降低数据使用成本 层次结构整个标签系统可分为多个主题（信用卡系统中的客户主题、卡片主题等），每个主题下又可根据标签数据的来源分为三类（基础类、行为类与衍生类） 基础类：如客户的基本信息，无需二次加工 行为类：如客户的历史行为（近一个月投资金额等），需要二次加工 衍生类：其他标签之间的逻辑组合 更新规则 基础类：静态标签，使用增量更新方式 行为类：动态标签，可采用周期性全量更新 衍生类：不存储标签值，仅存储标签之间的计算逻辑 ，无需更新 数据自助营销平台 - 数据产生价值最直接的途径作用与意义 自动化，提升工作效率 降低营销成本，提高用户体验 个性化营销，提升响应率 e.g. 某一营销活动（为促动低消费频次的客户用卡，提高卡均消费金额），期望不同的客户收到不同的营销短信。可通过营销平台限定仅6个月用卡次数 &lt; 10，月消费1800满3个月（略高于历史上的月均卡均消费），即可获得免费的化妆品（偏好标签）。 统一管理，便于后续效果追踪 其中可以看到，各种营销活动规则下的条件来源于标签系统，所以标签系统是基础！ 实时数据营销除了传统的批量营销方式（如优惠券即将过期短信提醒等），还有一种“基于场景的营销”，如你到加油站加油，刷卡付款后会立马收到某汽车润滑剂的促销信息。 从技术上来看，就是引入“消息队列”（Kafka、ActiveMQ等），将用户基于场景的“动作”转化为一个“消息” 给到数据营销平台，根据匹配的营销规则进行实时处理，反馈结果给客户。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[D3学习系列（二） 弦图绘制]]></title>
      <url>%2F2017%2F03%2F31%2FD3%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%88%E4%BA%8C%EF%BC%89-%E5%BC%A6%E5%9B%BE%E7%BB%98%E5%88%B6%2F</url>
      <content type="text"><![CDATA[「什么时候用弦图」Chord Diagram主要是用来表示多个节点之间的关系，假设我们要表示5个节点之间的关系，那么输入的矩阵是下面这个样子，且必须是方阵。节点A的长度是元素A所在行的总和，就是(A, A)、(A, B)、(A, C)、(A, D)、(A, E)的和。图中C与D之间的弦表示C和D相关，与C相接的弧长实际上是(C, D)的值。 「绘制弦图」导入初始数据12345678var city_name = [ "北京" , "上海" , "广州" , "深圳" , "香港" ];var population = [ [ 1000, 3045 , 4567 , 1234 , 3714 ], [ 3214, 2000 , 2060 , 124 , 3234 ], [ 8761, 6545 , 3000 , 8045 , 647 ], [ 3211, 1067 , 3214 , 4000 , 1006 ], [ 2146, 1034 , 6745 , 4764 , 5000 ] ]; 布局（转换数据）12345678// 弦布局var chord_layout = d3.layout.chord() .padding(0.03) .sortSubgroups(d3.descending) .matrix(population);// 布局转化数据var groups = chord_layout.groups();var chords = chord_layout.chords(); padding(0.03)表示弧与弧之间的间隔，population是之前输入的人口数据。经过布局之后会生成两块，一块是groups，表示节点；另一块是chords，表示弦（连线），chords里面还会分source与target，表示连线的两端。 绘制画布SVG12345678910// svg画布var width = 600;var height = 600;var svg = d3.select("body") .append("svg") .attr("width",width) .attr('height', height) .append("g") .attr('transform', 'translate(' + width/2 + "," + height/2 + ")");var color20 = d3.scale.category20(); 先创建一个SVG元素，里面添加一个g元素同时设置平移属性（用来确定弦图的中心）。然后再在g元素添加2个g元素，分别用来装节点与弦，结构如下所示： &lt;svg&gt; －－&lt;g&gt; －－－－ &lt;g&gt;``&lt;/g&gt; －－－－ &lt;g&gt;``&lt;/g&gt; －－&lt;/g&gt;&lt;/svg&gt; 绘制节点（弧）12345678910111213141516171819202122232425262728293031323334353637383940// 弧生成器var innerRadius = width/2 * 0.7;var outerRadius = innerRadius * 1.1;var outer_arc = d3.svg.arc() .innerRadius(innerRadius) .outerRadius(outerRadius);// 绘制节点var g_outer = svg.append("g");g_outer.selectAll("path") .data(groups) .enter() .append("path") .style("fill",function(d) &#123; return color20(d.index); &#125;) .style("stroke",function(d) &#123; color20(d.index); &#125;) .attr("d",outer_arc) // 此处调用了弧生成器 ;// 节点文字g_outer.selectAll("text") .data(groups) .enter() .append("text") .each(function(d,i) &#123; // 对每个绑定的数据添加两个变量 d.angle = (d.startAngle + d.endAngle) / 2; d.name = city_name[i]; &#125;) .attr("dy",".35em") .attr('transform', function(d) &#123; // 平移属性 var result = "rotate(" + (d.angle*180/Math.PI) + ")"; result += "translate(0," + -1 * (outerRadius + 10) + ")"; if (d.angle &gt; Math.PI * 3 / 4 &amp;&amp; d.angle &lt; Math.PI * 5 / 4 ) result += "rotate(180)"; return result; &#125;) .text(function(d) &#123; return d.name; &#125;); 在标记文字的地方要注意： each()：表示对任何一个绑定数据的元素，都执行后面的无名函数 function(d,i) ，计算文字的角度与内容 transform()：不仅需要考虑文字的旋转角度与平移距离，还要考虑如果文字在下方是会是倒写的情况。 生成如下图： 绘制连线（弦）123456789101112131415161718// 弦生成器var inner_chord = d3.svg.chord() .radius(innerRadius);// 绘制内部弦var g_inner = svg.append("g") .attr("class","chord");g_inner.selectAll("path") .data(chords) .enter() .append("path") .attr("d",inner_chord) // 调用弦的路径值 .style("fill",function(d) &#123; return color20(d.source.index); &#125;) .style("opacity",1) ; 这样就生成了首页的弦图，但是当数据多了之后，会看不清节点与节点之间的关系，我们可以添加一些交互式的操作解决。如当鼠标移到该节点，只会显示与该节点相接的弦，其他的会被隐藏。这里我们定义一个fade函数，并在节点（弧）上通过mouseover与mouseout添加动作123456789101112131415function fade(opacity)&#123; return function(g,i)&#123; g_inner.selectAll("path") .filter(function(d) &#123; return d.source.index != i &amp;&amp; d.target.index != i; &#125;) .transition() .style("opacity",opacity); &#125;&#125;g_outer.selectAll("path") .on("mouseover",fade(0.0)) // 0.0完全透明 .on("mouseout",fade(1.0)) // 1.0完全不透明 ; 效果如图： 「源代码」123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;&lt;/title&gt; &lt;script src="http://d3js.org/d3.v3.min.js" charset="utf-8"&gt;&lt;/script&gt; &lt;style&gt; .chord path&#123; fill-opacity: 0.67; stroke: #000; stroke-width: 0.5px; &#125; &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;script&gt; // 初始数据 var city_name = [ "北京" , "上海" , "广州" , "深圳" , "香港" ]; var population = [ [ 1000, 3045 , 4567 , 1234 , 3714 ], [ 3214, 2000 , 2060 , 124 , 3234 ], [ 8761, 6545 , 3000 , 8045 , 647 ], [ 3211, 1067 , 3214 , 4000 , 1006 ], [ 2146, 1034 , 6745 , 4764 , 5000 ] ]; // 弦布局 var chord_layout = d3.layout.chord() .padding(0.03) .sortSubgroups(d3.descending) .matrix(population); // 布局转化数据 var groups = chord_layout.groups(); var chords = chord_layout.chords(); console.log(groups); console.log(chords); // svg画布 var width = 600; var height = 600; var svg = d3.select("body") .append("svg") .attr("width",width) .attr('height', height) .append("g") .attr('transform', 'translate(' + width/2 + "," + height/2 + ")"); var color20 = d3.scale.category20(); // 弧生成器 var innerRadius = width/2 * 0.7; var outerRadius = innerRadius * 1.1; var outer_arc = d3.svg.arc() .innerRadius(innerRadius) .outerRadius(outerRadius); // 绘制节点 function fade(opacity)&#123; return function(g,i)&#123; g_inner.selectAll("path") .filter(function(d) &#123; return d.source.index != i &amp;&amp; d.target.index != i; &#125;) .transition() .style("opacity",opacity); &#125; &#125; var g_outer = svg.append("g"); g_outer.selectAll("path") .data(groups) .enter() .append("path") .style("fill",function(d) &#123; return color20(d.index); &#125;) .style("stroke",function(d) &#123; color20(d.index); &#125;) .attr("d",outer_arc) // 此处调用了弧生成器 .on("mouseover",fade(0.0)) // 0.0完全透明 .on("mouseout",fade(1.0)) // 1.0完全不透明 ; g_outer.selectAll("text") .data(groups) .enter() .append("text") .each(function(d,i) &#123; // 对每个绑定的数据添加两个变量 d.angle = (d.startAngle + d.endAngle) / 2; d.name = city_name[i]; &#125;) .attr("dy",".35em") .attr('transform', function(d) &#123; // 平移属性 var result = "rotate(" + (d.angle*180/Math.PI) + ")"; result += "translate(0," + -1 * (outerRadius + 10) + ")"; if (d.angle &gt; Math.PI * 3 / 4 &amp;&amp; d.angle &lt; Math.PI * 5 / 4 ) result += "rotate(180)"; return result; &#125;) .text(function(d) &#123; return d.name; &#125;); // 弦生成器 var inner_chord = d3.svg.chord() .radius(innerRadius); // 绘制内部弦,一共有5*5=25条 var g_inner = svg.append("g") .attr("class","chord"); g_inner.selectAll("path") .data(chords) .enter() .append("path") .attr("d",inner_chord) // 调用弦的路径值 .style("fill",function(d) &#123; return color20(d.source.index); &#125;) .style("opacity",1) ; &lt;/script&gt; &lt;/body&gt;&lt;/html&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[D3学习系列（一） 基础知识与柱形图绘制]]></title>
      <url>%2F2017%2F03%2F25%2FD3%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%80%EF%BC%89%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E4%B8%8E%E6%9F%B1%E5%BD%A2%E5%9B%BE%E7%BB%98%E5%88%B6%2F</url>
      <content type="text"><![CDATA[「前言」最开始的初衷是想画个弦图（chord）与桑基图（sankey），真的很炫有没有！然而D3零基础的我表示源码看不懂，受到1万点暴击(+﹏+)~ 于是果断去恶补D3的基础知识，并加以整理同时加深对自己的印象。 「基础概念」选择集使用 d3.select() 或 d3.selectAll() 选择元素后返回的对象，就是选择集 无名函数function(d, i) 这个函数以后经常要使用到 d 代表数据，也就是与某元素绑定的数据。 i 代表索引，代表数据的索引号，从 0 开始。 「数据绑定」D3可以用两种函数来绑定数据： datum()： 绑定一个数据到选择集上，这里的数据并非一定要是number（数值型），也可以是string（字符串）、bollean（布尔型）和object（对象） data()： 绑定一个数组到选择集上，数组的各项值分别与选择集的各元素绑定，更常用 data() 函数的常用语法12345678910var dataset = [10,20,30,40,50];var body = d3.select("body");body.selectAll("p") //选择body中的所有p，但是目前还没有，所以是空集 .data(dataset) //绑定数组 .enter() //指定选择集的enter部分 .append("p") .text(function(d)&#123; return d; &#125;) 这里要解释下 Enter 的概念，它与Update、Exit是D3中三个非常重要的概念，处理的是当选择集和数据的数量关系不确定的情况。 如果数组为 [3, 6, 9, 12, 15]，将此数组绑定到三个 p 元素的选择集上。可以想象，会有两个数据没有元素与之对应，这时候 D3 会建立两个空的元素与数据对应，这一部分就称为 Enter。而有元素与数据对应的部分称为 Update。如果数组为 [3]，则会有两个元素没有数据绑定，那么没有数据绑定的部分被称为 Exit。示意图如下所示。 「柱形图」Bar Chart一般包括：矩形、坐标轴与文字。 矩形这里我们直接定义一个数组，用数组项对应矩形的长短（然而这种方法并不理想）。1var dataset = [50, 43, 120, 87, 99, 167, 142]; 定义一块SVG的绘制区域：1234567var width = 600; // SVG的宽度var height = 600; // SVG的长度var svg = d3.select("body") .append('svg') // body中添加SVG .attr('width', width) .attr('height', height); 定义三个我们要用的变量123var padding = &#123;top: 20, right: 20, bottom: 20, left: 20&#125;;var rectStep = 35;var rectWidth = 30; padding是svg内的最外一层区域，留一段空白宽度是为了防止图形绘制带svg区域外。rectStep表示前一个矩形到下一个矩形的距离（包括空白间隔），而rectWidth是矩形实际的宽度。说了这么多还是看图更易懂： 添加矩形元素123456789101112131415var rect = svg.selectAll("rect") .data(dataset) .enter() //获取enter部分 .append("rect") //添加rect元素，使其与绑定数组的长度一致 .attr("fill","steelblue") .attr("x",function(d,i)&#123; //设置X坐标 return padding.left + i * rectStep; &#125;) .attr("y",function(d,i)&#123; //设置Y坐标 return height - padding.bottom - d; &#125;) .attr("width",rectWidth) //设置矩形宽度，之前定义的 .attr("height",function(d)&#123; //设置矩形高度，即为数组中的各项值 return d &#125;); 因为数组dataset的长度为7，所以最后生成7个矩形。x与y坐标是矩形的左上角顶点。 这个坐标是相对应svg绘图区域来讲的，坐标原点位于左上角(0,0)。 一张图直接说明： 标签文字123456789101112131415161718var text = svg.selectAll(text) .data(dataset) .enter() .append("text") .attr("fill","white") .attr("font-size","14px") .attr("text-anchor","middle") .attr("x",function(d,i)&#123; //与矩形的X坐标一样 return padding.left + i * rectStep; &#125;) .attr("y",function(d)&#123; return height - padding.bottom - d; &#125;) .attr('dx', rectWidth/2) //x轴相对平移距离 .attr('dy', "1em") //em单位表示的是当前文字所占一行的高度 .text(function(d)&#123; //要显示的文字内容 return d; &#125;); 添加文字标签的方法与添加矩形元素方法相类似，不过颜色要与矩形的颜色区分。通过设置元素的text-anchor、x、y、dx与dy五个属性，让文字显示在每个矩形的正中心。 其中dx,dy表示相对(x,y)平移的大小，所以文本会从(x+dx,y+dy)位置开始显示，这个位置也叫起始位置。属性text-anchor有三个值：start、middle、end,，这里用middle表示文字中心位于起始位置上。 还是上图说明问题： 效果图： 坐标轴坐标轴的主直线由path构成，刻度由line绘制，刻度文字用text完成。之前我们直接用数值的大小来表示像素的大小，这里我们使用比例尺，定义如下：123456789101112131415161718192021222324// SVG画布var width = 600;var height = 600;var svg = d3.select("body").append('svg') .attr('width', width) .attr('height', height);// 坐标轴的线性比例尺var xScale = d3.scale.linear() .domain([0,10]) //定义域 .range([0,300]); //值域// 定义坐标轴var axis = d3.svg.axis() .scale(xScale) .orient("bottom") .ticks(5); //刻度的数量，这里显示5个//在 SVG 中添加一个分组元素，再将坐标轴的其他元素添加到里面var gAxis = svg.append("g") .attr("transform","translate(80,80)"); .call(axis)gAxis.attr('class', 'axis'); //添加一些样式，否则太太太丑了... call()函数的使用十分常见，这里使用的参数是前面定义的坐标轴axis，等价于axis(gAxis);的形式。效果图如下： 「柱形图的坐标轴」对初学者而言，这里的坑更多（老司机请无视）。主要是因为使用了比例尺之后，XY坐标轴、矩形长宽、刻度都要与之相对应。不要问我为什么知道这么多，都是泪…… 为矩形图定义比例尺123456789var xAxisWidth = 300; //x轴宽度var yAxisWidth = 300; //y轴宽度var xScale = d3.scale.ordinal() //x轴比例尺（序数比例尺） .domain(d3.range(dataset.length)) .rangeRoundBands([0,xAxisWidth],0.2);var yScale = d3.scale.linear() //y轴比例尺（线性比例尺） .domain([0,d3.max(dataset)]) .range([0,yAxisWidth]); 定义完比例尺之后，矩形的高度、位置都要用比例尺来计算。如此之后，仅需简单修改比例尺，图表就能自动伸缩，所以前面的矩形元素与矩形文字的代码都需要修改 矩形元素修改部分12345678910.attr("x",function(d,i)&#123; return padding.left + xScale(i); // return padding.left + i * rectStep;&#125;).attr("y",function(d,i)&#123; return height - padding.bottom - yScale(d); // return height - padding.bottom - d;&#125;).attr("width",xScale.rangeBand()) .attr("height",function(d)&#123; return yScale(d);&#125;) 标签文字修改部分1234567891011.attr("x",function(d,i)&#123; //与矩形的X坐标一样 return padding.left + xScale(i);&#125;).attr("y",function(d)&#123; return height - padding.bottom - yScale(d);&#125;).attr('dx', xScale.rangeBand()/2) //x轴相对平移距离.attr('dy', "1em") //em单位表示的是当前文字所占一行的高度.text(function(d)&#123; //要显示的文字内容 return d;&#125;); 定义坐标轴123456789var xAxis = d3.svg.axis() .scale(xScale) .orient("bottom");yScale.range([yAxisWidth,0]); //值域相反var yAxis = d3.svg.axis() .scale(yScale) .orient("left"); 此外还要注意，y轴坐标的值域要与原来相反，从最大值到最小值，否则最后会出现下面这种情况： 添加坐标轴元素1234567891011//添加x轴svg.append("g") .attr("class","axis") .attr("transform","translate(" + padding.left + "," + (height - padding.bottom) + ")") .call(xAxis);//添加y轴svg.append("g") .attr("class","axis") .attr("transform","translate(" + padding.left + "," + (height - padding.bottom - yAxisWidth) + ")") .call(yAxis); 这里要小心x轴、y轴平移到目标位置的距离，以及你设置padding前后左右的宽度，防止坐标轴跑到外面去（又是血与泪的教训）。 最后效果图： 完整源代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;&lt;/title&gt; &lt;script src="http://d3js.org/d3.v3.min.js" charset="utf-8"&gt;&lt;/script&gt; &lt;style&gt; .axis path, .axis line&#123; fill: none; stroke: black; shape-rendering: crispEdges; &#125; .axis text&#123; font-family: sans-serif; font-size: 11px; &#125; &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;script &gt; // 添加SVG画布 var dataset = [50, 43, 120, 87, 99, 167, 142]; var width = 600; // SVG的宽度 var height = 600; // SVG的长度 var svg = d3.select("body") .append('svg') // body中添加SVG .attr('width', width) .attr('height', height); var padding = &#123;top: 20, right: 20, bottom: 20, left: 30&#125;; // 定义数据与比例尺 var xAxisWidth = 300; //x轴宽度 var yAxisWidth = 300; //y轴宽度 var xScale = d3.scale.ordinal() //x轴比例尺（序数比例尺） .domain(d3.range(dataset.length)) .rangeRoundBands([0,xAxisWidth],0.2); var yScale = d3.scale.linear() //y轴比例尺（线性比例尺） .domain([0,d3.max(dataset)]) .range([0,yAxisWidth]); // 添加矩形和文字元素 var rect = svg.selectAll("rect") .data(dataset) .enter() //获取enter部分 .append("rect") //添加rect元素，使其与绑定数组的长度一致 .attr("fill","steelblue") .attr("x",function(d,i)&#123; //设置X坐标 // return padding.left + i * rectStep; return padding.left + xScale(i); &#125;) .attr("y",function(d,i)&#123; //设置Y坐标 // return height - padding.bottom - d; return height - padding.bottom - yScale(d); &#125;) .attr("width",xScale.rangeBand()) //设置矩形宽度 .attr("height",function(d)&#123; return yScale(d); &#125;) var text = svg.selectAll(text) .data(dataset) .enter() .append("text") .attr("fill","white") .attr("font-size","14px") .attr("text-anchor","middle") .attr("x",function(d,i)&#123; //与矩形的X坐标一样 return padding.left + xScale(i); &#125;) .attr("y",function(d)&#123; return height - padding.bottom - yScale(d); &#125;) .attr('dx', xScale.rangeBand()/2) //x轴相对平移距离 .attr('dy', "1em") //em单位表示的是当前文字所占一行的高度 .text(function(d)&#123; //要显示的文字内容 return d; &#125;); // 定义坐标轴 var xAxis = d3.svg.axis() .scale(xScale) .orient("bottom"); yScale.range([yAxisWidth,0]); var yAxis = d3.svg.axis() .scale(yScale) .orient("left"); // 添加坐标轴 svg.append("g") .attr("class","axis") .attr("transform","translate(" + padding.left + "," + (height - padding.bottom) + ")") .call(xAxis); svg.append("g") .attr("class","axis") .attr("transform","translate(" + padding.left + "," + (height - padding.bottom - yAxisWidth) + ")") .call(yAxis); &lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 「参考资料」 【Learning D3.JS】 【D3.js：Update、Enter、Exit】 【D3.js - 初体验】 【D3.js数据可视化系列教程】]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Semantic UI上手]]></title>
      <url>%2F2017%2F03%2F18%2FSemantic-UI%E4%B8%8A%E6%89%8B%2F</url>
      <content type="text"><![CDATA[最近使用Semantic UI这一CSS框架实现了上图的苹果静态官网首页，我只想说，要不要这么简单粗暴！它省去了你大量时间与经历，不必去重复造轮子。但如此的便利必然是付出了某种你还未发现的代价…… Semantic UI基础知识我们要了解一些基本的样式与技巧，并能通过使用“形容词”来改变样式。 【基本样式】首先，header中导入semantic样式，在body的div块中定义class=“ui segment”，基本效果如下 【使用“形容词”】其次，在div class = &quot;XXX&quot;中加上你想实现的“形容词” inverted + color vertical padded inverted 颜色反转，若不加颜色，则直接变成黑色，官网给出下面多种颜色选择 vertical消除两边的圆角、阴影，同一vertical作用下的多个segment之间缝隙消失， padded改变内距 Apple静态官网首页实现了解了必要的知识之后，赶紧来实践一番！ 【导航菜单栏】使用semantic自带的ui menu样式，第一个与最后两个使用图标插入，其余的直接输文字，这里有几个小点需要注意： fixed：固定菜单栏，下拉拖动时表头不会消失，一直悬浮在最上面 fitted：大小宽度自适应 nine item：九个图标居中显示 borderless：去除图案之间的白色间隔线 代码如下1234567891011121314151617181920212223&lt;div class="ui fixed fitted inverted borderless nine item menu"&gt; &lt;a href="#" class="item"&gt; &lt;div class="ui image"&gt; &lt;img src="images\appleicon.png" alt="" /&gt; &lt;/div&gt; &lt;/a&gt; &lt;a href="#" class="item"&gt;Mac&lt;/a&gt; &lt;a href="#" class="item"&gt;iPad&lt;/a&gt; &lt;a href="#" class="item"&gt;iPhone&lt;/a&gt; &lt;a href="#" class="item"&gt;Watch&lt;/a&gt; &lt;a href="#" class="item"&gt;Music&lt;/a&gt; &lt;a href="#" class="item"&gt;技术支持&lt;/a&gt; &lt;a href="#" class="item"&gt; &lt;div class="ui image"&gt; &lt;img src="images\searchicon.png" alt="" /&gt; &lt;/div&gt; &lt;/a&gt; &lt;a href="#" class="item"&gt; &lt;div class="ui image"&gt; &lt;img src="images\buyicon.png" alt="" /&gt; &lt;/div&gt; &lt;/a&gt;&lt;/div&gt; 【iPhone7大图】 使用ui image样式插入图片，其他注意点： basic：消除黑边 secondary：相当于下面的效果 但是在这里可以从视觉效果上去除图片下的底色，否则会是下面这样，要多难看有多难看… 代码如下12345&lt;div class="ui basic secondary vertical segment"&gt; &lt;div class="ui image"&gt; &lt;img src="images/banner.png" alt="" /&gt; &lt;/div&gt;&lt;/div&gt; 【四张小图】 代码如下12345678910111213141516&lt;div class="ui basic secondary vertical segment"&gt; &lt;div class="ui fitted text menu"&gt; &lt;div class="item"&gt; &lt;img class="ui image" src="images/img1.png" alt="" /&gt; &lt;/div&gt; &lt;div class="item"&gt; &lt;img class="ui image" src="images/img2.png" alt="" /&gt; &lt;/div&gt; &lt;div class="item"&gt; &lt;img class="ui image" src="images/img3.png" alt="" /&gt; &lt;/div&gt; &lt;div class="item"&gt; &lt;img class="ui image" src="images/img4.png" alt="" /&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt; 【最后文字】 使用嵌套制作网页ui segment -&gt; ui container，注意事项： very padded：内距变大 一条分割线：通过&lt;div class=&quot;ui divider&quot;&gt;&lt;/div&gt;方式“画出”一条分割线 grid：网格系统，使用five column分成五列 text menu：每段文字放在里面，且用vertical垂直排列 代码如下12345678910111213141516171819202122232425&lt;div class="ui vertical secondary very padded segment"&gt; &lt;div class="ui container"&gt; &lt;div class="sub header"&gt; 双镜头摄像头仅于 iPhone 7 Plus 提供。亮黑色外观仅于 128GB 及以上存储容量的机型提供。 &lt;/div&gt; &lt;div class="ui divider"&gt;&lt;/div&gt; &lt;div class="ui five column grid"&gt; &lt;div class="column"&gt; &lt;div class="ui vertical text menu"&gt; &lt;div class="item"&gt; &lt;h4&gt;Apple Store 商店&lt;/h4&gt; &lt;/div&gt; &lt;a class="item"&gt;查找零售店&lt;/a&gt; &lt;a class="item"&gt;iPad&lt;/a&gt; &lt;a class="item"&gt;iPhone&lt;/a&gt; &lt;a class="item"&gt;Watch&lt;/a&gt; &lt;a class="item"&gt;iPod&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;!-- 段落重复4遍ing --&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt; 好了，最后把‘导航菜单栏’、‘iPhone7大图’、‘四张小图’与‘最后文字’四块部分拼接起来，就实现了苹果官网首页的效果，耶~ 源代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;Apple&lt;/title&gt; &lt;link rel="stylesheet" href="css/semantic.css" media="screen" title="no title" charset="utf-8"&gt; &lt;/head&gt; &lt;body&gt; &lt;!-- 导航栏 --&gt; &lt;div class="ui fixed fitted inverted borderless nine item menu"&gt; &lt;a href="#" class="item"&gt; &lt;div class="ui image"&gt; &lt;img src="images\appleicon.png" alt="" /&gt; &lt;/div&gt; &lt;/a&gt; &lt;a href="#" class="item"&gt;Mac&lt;/a&gt; &lt;a href="#" class="item"&gt;iPad&lt;/a&gt; &lt;a href="#" class="item"&gt;iPhone&lt;/a&gt; &lt;a href="#" class="item"&gt;Watch&lt;/a&gt; &lt;a href="#" class="item"&gt;Music&lt;/a&gt; &lt;a href="#" class="item"&gt;技术支持&lt;/a&gt; &lt;a href="#" class="item"&gt; &lt;div class="ui image"&gt; &lt;img src="images\searchicon.png" alt="" /&gt; &lt;/div&gt; &lt;/a&gt; &lt;a href="#" class="item"&gt; &lt;div class="ui image"&gt; &lt;img src="images\buyicon.png" alt="" /&gt; &lt;/div&gt; &lt;/a&gt; &lt;/div&gt; &lt;!-- 表头图片 --&gt; &lt;div class="ui basic secondary vertical segment"&gt; &lt;div class="ui image"&gt; &lt;img src="images/banner.png" alt="" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;!-- 四张图、 --&gt; &lt;div class="ui basic secondary vertical segment"&gt; &lt;div class="ui fitted text menu"&gt; &lt;div class="item"&gt; &lt;img class="ui image" src="images/img1.png" alt="" /&gt; &lt;/div&gt; &lt;div class="item"&gt; &lt;img class="ui image" src="images/img2.png" alt="" /&gt; &lt;/div&gt; &lt;div class="item"&gt; &lt;img class="ui image" src="images/img3.png" alt="" /&gt; &lt;/div&gt; &lt;div class="item"&gt; &lt;img class="ui image" src="images/img4.png" alt="" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;!-- 最后文字 --&gt; &lt;div class="ui vertical secondary very padded segment"&gt; &lt;div class="ui container"&gt; &lt;div class="sub header"&gt; 双镜头摄像头仅于 iPhone 7 Plus 提供。亮黑色外观仅于 128GB 及以上存储容量的机型提供。 &lt;/div&gt; &lt;!-- 文字重复中 --&gt; &lt;div class="ui divider"&gt;&lt;/div&gt; &lt;div class="ui five column grid"&gt; &lt;div class="column"&gt; &lt;div class="ui vertical text menu"&gt; &lt;div class="item"&gt; &lt;h4&gt;Apple Store 商店&lt;/h4&gt; &lt;/div&gt; &lt;a class="item"&gt;查找零售店&lt;/a&gt; &lt;a class="item"&gt;iPad&lt;/a&gt; &lt;a class="item"&gt;iPhone&lt;/a&gt; &lt;a class="item"&gt;Watch&lt;/a&gt; &lt;a class="item"&gt;iPod&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="column"&gt; &lt;div class="ui vertical text menu"&gt; &lt;div class="item"&gt; &lt;h4&gt;Apple Store 商店&lt;/h4&gt; &lt;/div&gt; &lt;a class="item"&gt;查找零售店&lt;/a&gt; &lt;a class="item"&gt;iPad&lt;/a&gt; &lt;a class="item"&gt;iPhone&lt;/a&gt; &lt;a class="item"&gt;Watch&lt;/a&gt; &lt;a class="item"&gt;iPod&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="column"&gt; &lt;div class="ui vertical text menu"&gt; &lt;div class="item"&gt; &lt;h4&gt;Apple Store 商店&lt;/h4&gt; &lt;/div&gt; &lt;a class="item"&gt;查找零售店&lt;/a&gt; &lt;a class="item"&gt;iPad&lt;/a&gt; &lt;a class="item"&gt;iPhone&lt;/a&gt; &lt;a class="item"&gt;Watch&lt;/a&gt; &lt;a class="item"&gt;iPod&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="column"&gt; &lt;div class="ui vertical text menu"&gt; &lt;div class="item"&gt; &lt;h4&gt;Apple Store 商店&lt;/h4&gt; &lt;/div&gt; &lt;a class="item"&gt;查找零售店&lt;/a&gt; &lt;a class="item"&gt;iPad&lt;/a&gt; &lt;a class="item"&gt;iPhone&lt;/a&gt; &lt;a class="item"&gt;Watch&lt;/a&gt; &lt;a class="item"&gt;iPod&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="column"&gt; &lt;div class="ui vertical text menu"&gt; &lt;div class="item"&gt; &lt;h4&gt;Apple Store 商店&lt;/h4&gt; &lt;/div&gt; &lt;a class="item"&gt;查找零售店&lt;/a&gt; &lt;a class="item"&gt;iPad&lt;/a&gt; &lt;a class="item"&gt;iPhone&lt;/a&gt; &lt;a class="item"&gt;Watch&lt;/a&gt; &lt;a class="item"&gt;iPod&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 参考资料 Semantic UI 官网Semantic UI 中文文档]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[如何成为技术大牛]]></title>
      <url>%2F2017%2F03%2F15%2F%E5%A6%82%E4%BD%95%E6%88%90%E4%B8%BA%E6%8A%80%E6%9C%AF%E5%A4%A7%E7%89%9B%2F</url>
      <content type="text"><![CDATA[前几日朋友分享了一篇“技术大牛养成指南”，看完之后有种豁然开朗的感觉，这也许和我最近的状态有关，最近一直没想通的问题似乎在这篇文章中也得到解决。作者通过目标拆解，用可实践的方法来指导大家如何在日常生活与工作中去运用。 什么是1万小时理论成为顶级专家的唯一方法就是1万小时持续不断地练习，意味着每天如果花3小时来提升自己的技能，需要10年…（不能包括你每天的重复性工作时间，要从专业广度与深度上不断扩展） 如何找到1万小时 每天的起床前与睡前30分钟：你会感到每天平白无故比别人多了一、两个小时 利用或节省路途时间 周末4小时 如何坚持下去 分解等级 0~1年：菜鸟，需要手把手教 1~3年：初级，要别人带你 3~5年：高级，独挡一面，能带初级技术人员 5~8年：资深，独挡多面 8~10年：大牛，统筹规划，高屋建瓴 分解技能每一段目标持续2~3年，哪里不懂补哪里，最好以6个月为周期 分解行动把技能目标分解为具体要做的事，把6个月的目标分解为1个月的目标 如何在工作中提升自我掌握业务代码中的技术后期并不会让你提升经验值，必须打更高级的怪、刷副本，没有一直打小怪就能升到顶级。你要不断的提升自己的水平，然后面临更大的挑战，从而使自己水平更上一级。 Do more 去熟悉更多系统、业务、代码，不管是不是你所负责的 善于自学。「唯一不变的只有变化」，我们更加需要自学更多东西，因为真正等到要用的时候再来学已经没有时间了 Do better你负责的系统和业务，总有不合理和可以改进的地方。这些“不合理”和“可改进”的地方，都是更高级别的怪物，打完后能够增加更多的经验值。 Do exercise印第安人有一句谚语：I hear and I forget. I see and I remember. I do and I understand.其实方法很简单：learning、trying、teaching]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[《大数据与机器学习》读书笔记（一） 数据与数据平台]]></title>
      <url>%2F2017%2F03%2F12%2F%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%20%E6%95%B0%E6%8D%AE%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%2F</url>
      <content type="text"><![CDATA[数据环境与数据形态对于企业经营中产生的数据有三种形态： 生产数据：指某个生产系统的生产环境数据库中的数据。它会随着业务应用的变化而变化，是动态的，如用户的账户余额数据。 原始数据：对生产数据的解耦，包括数据脱敏、字段筛选、批量导出（将动态数据的“快照”保存下来）。其目的是为了防止生产数据与分析数据的数据直连，带来数据管理与应用的灾难 分析数据：对原始数据进行ETL之后的数据，主要从属性筛选、标准统一（如数据格式与字段含义的不一致）、优化存储（如创建索引，分区，分表存储）的角度进行ETL。 数据仓库平台数仓本质是解决大批量数据的入口与出口问题，为分析与应用提供支持。该书作者认为能稳定提供 “顺滑” 数据服务的数仓需要注下面两点： 更新规则： 分全量更新与增量更新两种方式。更新过程中要注意“部分提交”与“数据断档”问题，可行的解决方案是增加中间表，如图 存储规则： 分析发现，数仓用户使用的交易数据90%集中在近三个月，60%的作业仅集中在近一个月。所以可行的办法是“大表拆小表，小表组视图”，提高访问效率。 大数据平台之前一直把Hive与Hbase的概念混淆，趁此机会搞清楚。 Hbase Hive 基于HDFS的非关系型数据库（KV型） 关系型数据结构，是用SQL替代写MR的编程框架 物理表，适合存放非结构化的数据 纯逻辑表，本身不存储数据，完全依赖于HDFS和MR 处理数据是基于列的模式 基于MR处理数据,而MR是基于行的模式 HBase是为了支持弥补Hadoop对实时操作的缺陷的项目 Hive是建立在Hadoop之上为了减少MapReduce jobs编写工作的批处理系统 适合实时查询 适合查询分析统计]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[matplotlib绘图－斜上抛运动]]></title>
      <url>%2F2017%2F03%2F11%2Fmatplotlib%E8%BF%90%E7%94%A8%EF%BC%8D%E6%96%9C%E4%B8%8A%E6%8A%9B%E8%BF%90%E5%8A%A8%2F</url>
      <content type="text"><![CDATA[matplotlib是Python中绘制2D图形使用最多的库，可以很轻松的将数据图形化。本文绘制了斜上抛运动，下面是最终的效果。 （菲菲老师教得好，幸不辱命 (•‾̑⌣‾̑•)✧˖° ） 「准备工作」 导入所需数据包这里的animation.FuncAnimation（fig，update，generate，interval = 5）函数，是用于生成动态图片的。其中fig表示生成的图表对象；generate函数生成数据后传递给update函数更新，这样数据不断更新，图形也不停变化；interval表示时间间隔，设置的值越小，运动速度越快 123from matplotlib import pyplot as pltfrom matplotlib import animation import math 设置图形窗口参数 12345678910111213141516# 中文字体路径设置，防止中文不显示font=FontProperties(fname=r"c:\windows\fonts\simsun.ttc",size=14)# 初始化图形窗口fig = plt.figure()ax = fig.add_subplot(111) ax.set_aspect('equal')# 设置坐标轴的x,y取值范围xmin = 0ymin = 0ax = plt.axes(xlim = (xmin, xmax), ylim = (ymin, ymax)) # 创建一个圆，圆点在（0,0），半径为1circle = plt.Circle((xmin, ymin), 1)ax.add_patch(circle) 给定初始参数值 1234g = 9.8u = 30 # 斜上抛的初速度theta = 60 # 与水平方向的夹角θtheta_radians = math.radians(theta) # 返回一个角度的弧度值 计算衍生参数 1234t_flight= 2*u*math.sin(theta_radians)/g # 从A点到B点所需时间t_max = u*math.sin(theta_radians)/g # 上升到最大高度所需时间xmax = u*math.cos(theta_radians)*t_flight # AB两点的距离ymax = u*math.sin(theta)*t_max - 0.5*g*t_max**2 # 上升的最大高度 「制作动态效果」主要利用前面介绍的animation.FuncAnimation函数。于是我们需要构造generate与update函数，让它动起来~ generate函数123456#产生时间间隔参数（每个数据间隔为0.05），依次传递给updata函数 def generate(): t = 0 while t &lt; t_flight: t += 0.05 yield t update函数123456#更新时间间隔参数，从而不断改变圆的圆心坐标位置，让其移动 def update(t): x = u*math.cos(theta_radians)*t y = u*math.sin(theta_radians)*t - 0.5*g*t*t circle.center = x, y return circle, 打印相关信息12345def Print(): print (u"初始速度（米/秒）:",u) print (u"发射角度（度）",theta) print (u"飞行总时间（秒）",t_flight) print (u"飞行距离（米）",xmax) 动画函数123456789anim = animation.FuncAnimation(fig, update,generate,interval=10)# 附加信息anim= animation.FuncAnimation(fig, update,generate,interval=10)plt.title(u'导弹发射轨迹',fontproperties=font)plt.xlabel(u'水平距离(米)',fontproperties=font)plt.ylabel(u'导弹运行高度（米）',fontproperties=font)plt.show()Print() 最后就能看到首页的动态图了 ヾ(◍’౪`◍)ﾉﾞ]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[R数据可视化－动态、交互式地图神器（三）自定义Marker]]></title>
      <url>%2F2017%2F03%2F08%2FR%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%EF%BC%8D%E5%8A%A8%E6%80%81%E3%80%81%E4%BA%A4%E4%BA%92%E5%BC%8F%E5%9C%B0%E5%9B%BE%E7%A5%9E%E5%99%A8%EF%BC%88%E4%B8%89%EF%BC%89%E7%AC%A6%E5%8F%B7%E6%A0%87%E8%AE%B0%2F</url>
      <content type="text"><![CDATA[Leaflet/LeafletCN 系列R数据可视化－动态、交互式地图神器（一）概述与实现R数据可视化－动态、交互式地图神器（二）地图与定位 特别喜欢Leaflet的marker自定义，主要有以下几种标记方法 【标记】 addMarkers(popup,icon) awesomeMarker(icon,library, markerColor,iconColor ) addCircleMarker(popup,color,fillOpacity) 1234567891011- popup：文字描述- icon：自定义图标- icon：图表类型- library：图标库- markerColor：背景颜色- iconColor ：图标颜色- popup：文字描述- color：颜色- fillOpacity：透明度 【第一类方法举例】123456df = data.frame(Lat = 31+ rnorm(10,0,1), Lon = 121 + rnorm(10,0,1)) # 生成10个随机点df #传数据 %&gt;% leaflet() # 加载地图容器 %&gt;% addTiles() # 加载底图 %&gt;% addMarkers() # 加默认标记 这种是默认的图标 接下来自定义icon12345678910111213warIcons &lt;- iconList( #自定义icon图标 cat = makeIcon("cat.png", iconWidth = 60, iconHeight = 60, iconAnchorX = 30, iconAnchorY = 30), dog = makeIcon("dog.png", iconWidth = 60, iconHeight = 60, iconAnchorX = 30, iconAnchorY = 30)) geo %&gt;% leaflet() #加地图容器 %&gt;% addProviderTiles("Thunderforest.SpinalMap") #加地图底图 %&gt;% addMarkers(icon=~warIcons[type]) #使用自定义的icon 其中geo数据长这样 其中makeIcon用法123456makeIcon(iconUrl ,iconWidth,iconHeight,iconAnchorX ,iconAnchorY) - iconUrl : 图标的url地址 - iconWidth ：图标的宽度 - iconHeight: 图标的高度 - iconAnchorX :图标的中心点x轴偏移（以左上角为0,0) - iconAnchorY :图标的中心点Y轴偏移（以左上角为0,0) 效果 【第二类方法举例】可以在library参数中设定你希望选择的图标库，有以下几个： fontIcons glyphicon Ionicons 如：1234567myIcon = makeAwesomeIcon(icon = "book", library = "glyphicon",markerColor = "purple")df%&gt;% leaflet() %&gt;% setView() %&gt;% addProviderTiles("NASAGIBS.ViirsEarthAtNight2012") %&gt;% addAwesomeMarkers(icon=myIcon) 效果 【第三类方法举例】addCircleMarkers()方法更简单，直接把点作为一个镶边的圆（或者说圆符号）绘制到地图上，如：123leaflet(df) %&gt;% addProviderTiles("CartoDB.Positron")%&gt;% addCircleMarkers() 效果]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hexo搭建个人博客]]></title>
      <url>%2F2017%2F03%2F05%2FHexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%2F</url>
      <content type="text"><![CDATA[前言人啊，总有那么一瞬间，想把自己各种美好与不美好的瞬间，经历与感悟给记录下来。当自己回过头再来看的时候，也许会哭，会笑，酸甜苦辣，各有滋味。当这些点点滴滴汇聚起来之后，估计我会仰天大吼：这一世没白活！ 正文这个周末在网上各种找资料、跨过无数坑之后，个人博客算是初步完成了。 【目标与要求】 美观：对审美有一定要求，有相对不错的外观 功能：起码能分类、打标签、各种时间维度能归档 学习成本：语言、代码相对更容易，学习成本相对较低 时间与金钱成本：最好不用花钱（能省点是一点，我的土壕朋友请无视），不用花太多时间在系统运维 【产品选型】 第三方博客平台，如CSDN、博客园、新浪、豆瓣等。可直接写文章，但模板、样式固定，不算难看也不算好看（简书整体不错，简约风，但是不能带标签，而且鸡汤较多…） 博客工具，部分支持MarkDown语法，免去把文本转化为HTML的痛苦，主要有： wordpress：功能强大，要有主机与域名（免费有限制，正经使用的要花钱购买、备案，还要考虑审批部门的效率…你懂的），折腾太费事费时 ghost：类似wordpress，相对较重，也是动态网站、需要依赖数据库 Jekyll：静态文件生成器，支持Markdown，能部署到github。依赖较多库，windows用户不友好，无本地预览功能 hexo：安装简单，依赖少（仅node），中文支持好（台湾人写的），命令少，易于记忆，可本地实现简单预览，支持markdown。 果断选择了Hexo，下面是介绍下主角： “A fast, simple &amp; powerful blog framework, powered by Node.js.”（官方版）。它是一个Node的静态博客框架，因此没有数据库。可直接部署到github上。好处大大的：省去服务器成本，减少系统运维(系统管理、备份、网络)。 【安装操作】 安装node.js：用来生成静态页面[点击安装node] 注册Github账号：欢迎加入全球最大的同性交友网站ヾ(◍’౪`◍)ﾉﾞ。不限流量、免费提供开放的托管静态页面的网站。 注意！新建的Repo一定要与你的github用户名一模一样，如[username].github.io 安装Git：用于把本地的Hexo内容沟通,传输,部署到Github上。安装教程可参考廖雪峰的博客[点击安装Git] 以下步骤一定要做！ 12$ git config --global user.name "Your Name"$ git config --global user.email "email@example.com" 安装Hexo 在git bash中敲： 1npm install hexo-cli -g 【构建博客】 初始化 创建一个新的文件夹（放你博客的地方），右键点击Git Bash Here，执行： 1hexo init 可以通过以下命令查看是否执行成功 1hexo s 出现以下代码，恭喜成功~，并在浏览器输入：http://localhost:4000/ 进行本地预览（默认端口4000） 12INFO Start processingINFO Hexo is running at http://localhost:4000/. Press Ctrl+C to stop. 配置与部署 我们看到之前创建的博客所在文件夹结构： Blog ｜ ｜－－ .deploy_git ｜－－ node_modules ｜－－ scaffolds ｜－－ source ｜－－ themes ｜－－ _config.yml ｜－－ _gitinore ｜－－ db.json ｜－－ package.json ｜－－ debug.log 现在需要_config.yml与我们github用户名对应的仓库建立联系。打开_config.yml文件，拉到最后对应修改： 123deploy:type: gitrepo: http://github.com/[username]/[username].github.io 并部署： 123hexo clean # 清除缓存hexo generate # 生成静态页面hexo deploy # 上传部署 到现在，我们的“简装房”就有了，后续需要通过主题替换与各种功能设置，来鸟枪换大炮，变成“精装房”(▰˘◡˘▰) ~。 参考资料 Hexo 中文文档 【包涵：文档、API、插件、主题】NexT 使用文档【包含：开始使用、主题配置、第三方服务、内建标签、常见问题】]]></content>
    </entry>

    
  
  
</search>
